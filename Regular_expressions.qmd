---
title: "Regular expressions"
author: 
    - name: "Vladimir Buskin"
      affiliations: 
        - "Catholic University of Eichstätt-Ingolstadt"
      orcid: "0009-0005-5824-1012"
    - name: "Thomas Brunner"
      affiliations:
        - "Catholic University of Eichstätt-Ingolstadt"
format:
  html:
    self-contained: true
    theme: default
    toc: true
    number-sections: true
    slide-number: true
    incremental: false
    slide-level: 3
    scrollable: true
    
editor: visual
---

## Preparation

::: callout-tip
## Script

You can find the full R script associated with this unit
[here](https://osf.io/uhdns).
:::

## Suggested reading

> @lange_corpus_2020: Chapter 3.7
>
> [Detailed
> cheatsheet](https://images.datacamp.com/image/upload/v1665049611/Marketing/Blog/Regular_Expressions_Cheat_Sheet.pdf)
> (DataCamp)

## Regular expressions

**Regular expressions** (or 'regex') help us find more complex patterns
in strings of text. Suppose we are interested in finding all
inflectional forms of the lemma PROVIDE in a corpus, i.e., *provide,
provides, providing* and *provided*. Insteading of searching for all
forms individually, we can construct a regular expression of the form

$$
\text{provid(e(s)? | ing | ed)}
$$ which can be read as

> 'Match the sequence of letters \<provid\> as well as when it is
> followed by the groups of letters \<es\> or \<ing\> or \<ed\>. Also
> make the \<s\> in \<es\> optional.'

Notice how optionality is signified by the `?` operator and alternatives
by `|`.

To activate regular expression in a `kwic()` query, the `valuetype`
argument has to be set to `"regex"`:

```{r, eval = TRUE}

# Load library and corpus
library(quanteda)
ICE_GB <- readRDS("ICE_GB.RDS")

# Perform query
kwic_provide <- kwic(ICE_GB,
                     "provid(e(s)?|ing|ed)",
                     valuetype = "regex",
                     window = 20)
```

The number of hits has more than doubled. However, upon closer
inspection, we'll notice a few false positives, namely *providential*,
*provider* and *providers*:

```{r}
table(kwic_provide$keyword)
```

There are two ways to handle the output:

1.  **Refine the search expression** further to only match those cases
    of interest.
2.  Manually **sort out irrelevant cases** during qualitative annotation
    in a spreadsheet software.

As a rule of thumb, you should consider improving your search expression
if you obtain hundreds or even thousands of false hits. Should there be
only few false positives, it's usually easier to simply mark them as
"irrelevant" in your spreadsheet. A full workflow is demonstrated in
unit [13. Data annotation](Annotation.qmd).

## A RegEx Cheatsheet

### Basic functions

| **Command** | **Definition** | **Example** | **Finds**           |
|-------------|----------------|-------------|---------------------|
|             |                | `python`    | *python*            |
| `.`         | Any character  | `.ython`    | *aython, bython...* |

### Character classes and alternatives

| **Command** | **Definition**                               | **Example**     | **Finds**                       |
|-----------------|----------------------|-----------------|-----------------|
| `[abc]`     | Class of characters                          | `[jp]ython`     | *jython, python*                |
| `[^pP]`     | Excluded class of characters                 | `[^pP]ython`    | everything but *python, Python* |
| `(...|...)` | Alternatives linked by logical operator `or` | `P(ython|eter)` | *Python, Peter*                 |

### Quantifiers

| **Command** | **Definition**                                | **Example**   | **Finds**                     |
|-----------------|----------------------|-----------------|-----------------|
| `?`         | One or zero instances of the preceding symbol | `Py?thon`     | *Python, Pthon*               |
| `*`         | No matter how many times — also zero          | `Py*thon`     | *Python, Pthon, Pyyyython...* |
|             |                                               | `P[Yy]*thon`  | *Python, Pthon, PyYYython...* |
| `+`         | No matter how many times but at least once    | `Py+thon`     | *Python, Pyyython, Pyyyython* |
| `{1,3}`     | `{min, max}`                                  | `Py{1,3}thon` | *Python, Pyython, Pyyython*   |

### Pre-defined character classes

::: callout-note
The double backslashes (`\\`) shown here are specific to the `quanteda`
R package. In most other programming languages including Python, you
only need a single backslash (e.g., `\w`, `\d`, `\s`). This
double-escaping is an R-specific requirement due to how R handles string
literals.
:::

| **Command** | **Definition**                              | **Example**      | **Finds**                        |
|-----------------|---------------------|-----------------|-----------------|
| `\\w`       | All alphanumeric characters (A-Z, a-z, 0-9) | `\\w+ing`        | *walking*, *running*, *42ing*    |
| `\\W`       | All non-alphanumeric characters             | `hello\\W+world` | *hello world*, *hello!!!world*   |
| `\\d`       | All decimal numbers (0-9)                   | `\\d{3}-\\d{4}`  | *555-1234*, *867-5309*           |
| `\\D`       | Everything which is not a decimal number    | `\\D+`           | *Hello!*, *Python_code*          |
| `\\s`       | Empty space                                 | `word\\s+word`   | *word word*                      |
| `\\b`       | Word boundary                               | `\\bpython\\b`   | Matches *python* as a whole word |

## Querying parsed corpora

The range of linguistic patterns to be matched can be extended further
if the corpus contains additional metadata, such as the part of speech
(POS) of a token. POS-tagged corpora open up the option of looking for
more abstract patterns, such as all instances of the verb *eat* that are
followed by a pronoun or noun:

```{r, output = FALSE}
# Load library and corpus
ICE_GB_POS <- readRDS("ICE_GB_POS.RDS")

# Perform query
kwic_provide_POS2 <- kwic(ICE_GB_POS,
                     phrase("\\b(ate|eat(s|ing|en)?)_VERB\\b _(PRON|NOUN)"),
                     valuetype = "regex",
                     window = 5)

head(kwic_provide_POS2)
```

```{r, echo = F}
library(kableExtra)

kwic_provide_POS2 %>% 
  head() %>% 
  kbl() %>% 
  kable_classic(full_width = F, html_font = "Cambria")
```

One R package that supplies functions for tokenisation, POS-tagging and
even dependency parsing for dozens of languages is `udpipe`. They all
rely on one common set of tags known as **Universal Dependencies**,
which are listed here:

::: {.callout-tip title="Universial dependencies -- Tagset" collapse="true"}
Cf. <https://universaldependencies.org/u/pos/>.

| POS Tag | Description                                                                                               |
|------------------|------------------------------------------------------|
| ADJ     | Adjective: describes a noun (e.g., *big*, *old*, *green*, *first*)                                        |
| ADP     | Adposition: prepositions and postpositions (e.g., *in*, *to*, *over*)                                     |
| ADV     | Adverb: modifies verbs, adjectives, or other adverbs (e.g., *quickly*, *very*)                            |
| AUX     | Auxiliary: helps form verb tenses, moods, or voices (e.g., *is*, *have*, *will*)                          |
| CCONJ   | Coordinating conjunction: links words, phrases, or clauses (e.g., *and*, *or*, *but*)                     |
| DET     | Determiner: introduces nouns (e.g., *the*, *a*, *some*, *my*)                                             |
| INTJ    | Interjection: expresses emotion or reaction (e.g., *oh*, *wow*, *hello*)                                  |
| NOUN    | Noun: person, place, thing, or concept (e.g., *cat*, *city*, *idea*)                                      |
| NUM     | Numeral: expresses a number or ranking (e.g., *one*, *two*, *second*)                                     |
| PART    | Particle: adds meaning without being an independent word class (e.g., *not*, *to* as in *to run*)         |
| PRON    | Pronoun: replaces nouns (e.g., *he*, *she*, *they*, *it*)                                                 |
| PROPN   | Proper noun: names specific entities (e.g., *London*, *Vladimir*)                                         |
| PUNCT   | Punctuation: marks boundaries in text (*.* , *!* *?*)                                                     |
| SCONJ   | Subordinating conjunction: links clauses, often indicating dependency (e.g., *if*, *because*, *although*) |
| SYM     | Symbol: non-alphanumeric symbol (e.g., *%*, *&*, *\#*)                                                    |
| VERB    | Verb: action or state (e.g., *run*, *be*, *have*)                                                         |
| X       | Other: used when a word doesn't fit into other categories                                                 |
:::

## Working with other corpora

Some corpus platforms such as [BNCweb](https://bncweb.lancs.ac.uk),
[CQPweb](https://cqpweb.lancs.ac.uk) or our local [KU
corpora](ku.de/corpora)[^regular_expressions-1] support a specialised
query syntax known as **CQP** (**C**orpus **Q**uery **P**rocessor),
which enables users to query for strings with specific meta-attributes
(text category, age, gender etc.).

[^regular_expressions-1]: Note that the corpus platform of the Catholic
    University of Eichstätt-Ingolstadt, which was set up by Dr. Thomas
    Brunner, is only accessible to students or staff via the local
    **eduroam** network or a **VPN client** which holds their
    credentials.

### Basic use

Once signed in on any of these platforms, the user interface will generally follow this layout:

![CQP query of PROVIDE in the GloWbE corpus](CQP_example.png)

-   To select a different corpus, navigate to `CQPweb main menu` under
    **About CQPweb** in the left menu bar.

-  To restrict search results to specific parts of the corpus, select `Restricted query` and choose the relevant text categories, varieties, etc.

You can now enter a search expression into the white box using the following pattern:

```{r, eval = F}
[attribute = "property"]
```

For example, to retrieve all inflectional forms of the verb
*provide*, enter:

```{r, eval = F}
[lemma = "provide"]
```

To search for a word with a specific part-of-speech (POS) tag -- such as **like** used as a preposition -- use:

```{r, eval = F}
[word = "like" & pos = "ii"]
```

For a full list of POS-tags, refer to:

-   [CLAWS5](https://ucrel.lancs.ac.uk/bnc2/bnc2guide.htm#tagset) (for **BNC**)
-   [CLAWS7](https://ucrel.lancs.ac.uk/claws7tags.html) (for **COCA** and **GloWbE**)

### Exporting and importing your results

To export your KWIC-hits, select `Download` in the top-right corner and
specify your output options (e.g., the size of the search window or the
speaker metadata). While you can immediately read the downloaded `concordance.txt` file into R,  it’s advisable to first perform some **manual clean-up** in spreadsheet software (e.g., MS Excel). This ensures all columns and rows are complete and properly formatted.

To do this in Excel: 

1.    Navigate to `File > Import > Text file`.

2.    Select your file and choose `Delimited`.

3.    Click Next, select `Tab` as the delimiter, then click `Next > Finish`.


Make sure to **save your file**, ideally with the extension `.xlsx`.

From here, please refer to the unit [Import/export data](Importing_exporting.qmd) for further steps.


## Exercises

::: callout-tip
## Solutions

You can find the solutions to the exercises
[here](https://osf.io/xaumr).
:::

::: {#exr-regex-1}
How could you refine the search expression for PROVIDE
`"provid(e(s)?|ing|ed)"` to get rid of the irrelevant cases?
:::

::: {#exr-regex-2}
Write elegant regular expressions which find all inflectional forms of
the following verbs:

-   *accept*

-   *attach*

-   *swim*

-   *know*

-   *forget*
:::

::: {#exr-regex-3}
Find all nouns ending in *-er*.
:::

::: {#exr-regex-4}
Find all four-digit numbers.
:::

::: {#exr-regex-5}
Find all verbs that are followed by a preposition.
:::
