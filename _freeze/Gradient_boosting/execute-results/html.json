{
  "hash": "77867ab6220cafe217fe0a62867d1c3b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Gradient boosting\"\nauthor: \n  - name: \"Vladimir Buskin\"\ndate: 11-12-2024\nabstract: > \n  Gradient boosting constitutes a powerful extension of tree-based methods and is generally appreciated for its high predictive performance. Nevertheless, this family of methods, which includes implementations such as AdaBoost, XGBoost, and CatBoost, among many others, is not yet established in corpus-linguistic statistics. A practical scenario is presented to introduce the core ideas of gradient boosting, demonstrate its application to linguistic data as well as point out its advantages and drawbacks.\nkeywords: \"Machine learning, gradient descent, loss function, regularization\"\ncitation:\n  type: \"article\"\n  title: \"Gradient boosting\"\n  container-title: \"Introduction to R for Linguists\" # Add this\n  author: \"Vladimir Buskin\"                         # Add this\n  issued: \"2024\"                                    # Add this\n  url: \"https://example.com/summarizing-output\"\nformat:\n  html:\n    self-contained: true\n    theme: default\n    toc: true\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 3\n    scrollable: true\neditor: visual\nbibliography: R.bib\n---\n\n\n## Recommended reading\n\n> @james_introduction_2021: Chapter 8.2\n>\n> @hastie2017: Chapter 10\n\n## Preparation\n\n## Boosting\n\n::: callout-warning\nThis page is still under construction. More content will be added soon!\n:::\n\n::: {.citation}\n:::\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n## How to cite\n\nTo cite this chapter:\n\nVladimir Buskin (2024). Gradient boosting. In . https://example.com/summarizing-output\n```\n\n\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}