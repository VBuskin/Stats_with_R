{
  "hash": "e6372c5c91f9383e4cb1220fea1d0a12",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Import/export data\"\nauthor: Vladimir Buskin\nformat:\n  html:\n    self-contained: true\n    theme: default\n    toc: true\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 3\n    scrollable: true\n    \neditor: visual\n---\n\n\n::: callout-tip\n## Script\n\nYou can find the full R script associated with this unit\n[here](https://osf.io/puyrf).\n:::\n\n## Recommended reading\n\n> @winter_statistics_2020: Chapter 1.11\n\n## Preparation\n\nThe first section of an R script should always specify the libraries\nthat are needed for executing the code to follow. In this unit, we will\nneed `readxl` and `writexl` to aid us with importing MS Excel files.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(writexl)\n```\n:::\n\n\nIf you haven't installed them yet, the R console will throw an error\nmessage. For instructions on how to install an R package, consult the\nunit on [Libraries](Libraries.qmd).\n\n### Exporting data\n\nAssume we'd like to export our data frame with word frequencies to a\nlocal file on our system. Let's briefly regenerate the data frame:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate data frame\ndata <- data.frame(lemma = c(\"start\", \"enjoy\", \"begin\", \"help\"), \n                   frequency = c(418, 139, 337, 281))\n\n# Print contents\nprint(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  lemma frequency\n1 start       418\n2 enjoy       139\n3 begin       337\n4  help       281\n```\n\n\n:::\n:::\n\n\nThere are two common formats in which tabular data can be stored:\n\n-   as .**csv**-files ('**c**omma-**s**eparated **v**alues'; native\n    format of LibreOffice Calc)\n\n-   as .**xls**/.**xlsx**-files (Microsoft Excel)\n\n::: {.callout-note collapse=\"true\" title=\"Export to CSV\"}\nTo save our `data` data frame in .csv-format, we can use the\n`write_table()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(data, \"frequency_data.csv\")\n```\n:::\n\n\nThe file is now stored at the location of your current R script. You can\nopen this file ...\n\n-   in **LibreOffice**\n\n-   in **Microsoft Excel** via `File` \\> `Import` \\> `CSV file` \\>\n    Select the file \\> `Delimited` and then `Next` \\> `Comma` and `Next`\n    \\> `General` and `Finish`.\n\nClearly, opening CSV files in MS Excel is quite cumbersome, which is why\nit's better to export it as an Excel file directly.\n:::\n\n::: {.callout-note collapse=\"true\" title=\"Export to Excel\"}\nWe use the `write_xlsx()` function provided by the package `writexl`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_xlsx(data, \"frequency_data.xlsx\")\n```\n:::\n\n\nThe file is now stored at the location of your currently active R\nscript. You should now be able to open it in MS Excel without any\nissues.\n:::\n\n### Importing data {#sec-import}\n\nLet's read the two files back into R.\n\n::: {.callout-note collapse=\"true\" title=\"Import from CSV\"}\nTo import the CSV file, we can use the `read.csv()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimported_csv <- read.csv(\"frequency_data.csv\")\nprint(imported_csv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  X lemma frequency\n1 1 start       418\n2 2 enjoy       139\n3 3 begin       337\n4 4  help       281\n```\n\n\n:::\n:::\n\n\nIt appears that `read.csv()` has also written the row numbers to the\nfile. This is not the desired outcome and can be prevented by adding an\nadditional argument:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimported_csv <- read.csv(\"frequency_data.csv\", row.names = 1)\nprint(imported_csv) # Problem solved!\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  lemma frequency\n1 start       418\n2 enjoy       139\n3 begin       337\n4  help       281\n```\n\n\n:::\n:::\n\n\n::: {.callout-warning collapse=\"true\" title=\"A note on file encodings and separators\"}\nWhen working with CSV files, you may encounter issues with character\nencodings and separators, especially when:\n\n-   working with files from different operating systems,\n-   dealing with text containing special characters (é, ü, ñ, etc.), or\n-   importing files created in different regions (e.g., European vs.\n    US).\n\nThe most common encoding-related parameters for read.csv() are:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# For files with special characters (recommended default)\ndata <- read.csv(\"myfile.csv\", encoding = \"UTF-8\")\n\n# For files from Windows systems\ndata <- read.csv(\"myfile.csv\", encoding = \"latin1\")\n\n# For files using semicolons and commas as decimal points\ndata <- read.csv(\"myfile.csv\", sep = \";\", dec = \",\")\n```\n:::\n\n\n-   If you see garbled text like Ã© instead of é, try specifying\n    `encoding = \"UTF-8\"`.\n-   If your data appears in a single column, check if your file uses\n    semicolons (`;`) instead of commas (`,`) as separators.\n-   If numeric values are incorrect, verify whether the file uses commas\n    or periods as decimal separators.\n:::\n:::\n\n::: {.callout-note collapse=\"true\" title=\"Import from Excel\"}\nFor importing the Excel file, we'll use the `read_xlsx()` function from\nthe `readxl` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimported_excel <- read_xlsx(\"frequency_data.xlsx\")\nprint(imported_excel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  lemma frequency\n  <chr>     <dbl>\n1 start       418\n2 enjoy       139\n3 begin       337\n4 help        281\n```\n\n\n:::\n:::\n\n:::\n\nThat's it! Nevertheless, remember to always check your imported data to\nensure it has been read in correctly, especially when working with CSV\nfiles.\n\n## A convenient alternative: RDS files\n\nIf the main goal is to save an intermediary result and make it available\nfor later use, the most efficient solution is to save the object to a\nlocal R data file ending in `.RDS`. Since it compressed data, .RDS files\ncan be considered analogous to .zip files, which are very commonly used\nfor other data types.\n\nIn practice, we use the `saveRDS()` function and supply it with ...\n\n-   ... an R object (e.g., a vector, data frame, matrix, graphs,\n    statistical models -- anything goes!) as well as\n\n-   ... the desired name of the file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save data frame \"data\" to the file \"frequency_data.RDS\"\nsaveRDS(data, \"frequency_data.RDS\")\n```\n:::\n\n\nTo read a file back in, we need to indicate the file name (or the full\nfile path if the file is located in a different folder).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read in \"frequency_data.RDS\" and assign the contents to \"data2\"\ndata2 <- readRDS(\"frequency_data.RDS\")\n\n# Verify contents\nprint(data2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  lemma frequency\n1 start       418\n2 enjoy       139\n3 begin       337\n4  help       281\n```\n\n\n:::\n:::\n\n\n## Exercises\n\n::: {#exr-impexp-1}\nRead in the file `SCOPE_reduced.RDS` into a variable named `SCOPE`. It\ncontains data from the the South Carolina Psycholinguistic Metabase\n[@gaoSCOPESouthCarolina2022], specifically:\n\n-   Number of meanings (`Nsenses_WordNet`)\n\n-    Emotional valence ratings, which describe the pleasantness of a\n    lexical stimulus on a scale from 1 to 9 (`Valence_Warr`)\n\n-    Data for nearly 200,000 words\n:::\n\n::: {#exr-impexp-2}\nUsing this database, retrieve\n\n1.  the number of meanings for the verbs *start*, *enjoy*, *begin*,\n    *help*. Store them in a data frame with the name `senses_df`.\n2.  emotional valence ratings for the words *fun*, *love*, *vacation*,\n    *war*, *politics*, *failure*, *table*. Store them in a data frame,\n    and name it `valence_df`.\n\nWhat do you notice about the valence ratings? Do they align with your\nintuitions about these words' emotional content?\n\n:::callout-tip\n\nThis task is very similar to @exr-df-3!\n\n:::\n\n:::\n\n::: {#exr-impexp-3}\nExport `senses_df` and `valence_df` both as .csv and .xlsx files, and\nread them back into R.\n\n\n::: {.cell}\n\n:::\n\n:::\n\n::: {#exr-impexp-4}\n\nSeparators determine how tabular data is stored internally. Investigate what happens when you read in `frequency_data.csv` with different separator settings:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Comma separator (default)\nimported_csv1 <- read.csv(\"frequency_data.csv\", sep = \",\")\nprint(imported_csv1)\n\n# Tab separator\nimported_csv2 <- read.csv(\"frequency_data.csv\", sep = \"\\t\")\nprint(imported_csv2)\n\n# Semi-colon separator\nimported_csv3 <- read.csv(\"frequency_data.csv\", sep = \";\")\nprint(imported_csv3)\n```\n:::\n\n\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}