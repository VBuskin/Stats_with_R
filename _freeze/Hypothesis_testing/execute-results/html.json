{
  "hash": "e8c36d89992546cc469a9e45b4419c3a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hypothesis testing\"\nauthor: Vladimir Buskin\nformat:\n  html:\n    self-contained: true\n    code-fold: false\n    theme: default\n    toc: true\n    toc-depth: 4\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 3\n    scrollable: true\neditor: visual\nbibliography: R.bib\n---\n\n\n## Suggested reading\n\nFor linguists:\n\n> @gries_statistics_2021: Chapter 1.3.2\n\nGeneral:\n\n> @baguleySeriousStatsGuide2012: Chapter 4\n>\n> @agrestiFoundationsStatisticsData2022: Chapter 5\n\n## Hypothesis testing {#sec-hyp}\n\nThe null hypothesis significance testing (NHST) framework offers\nresearchers a convenient way of testing theoretical assumptions about a\npopulation of interest (e.g., a speech community). This involves setting\nup a set of falsifiable statistical hypotheses that predict the presence\nor absence of certain patterns in the data. These are known as the\n**null hypothesis** $H_0$ and the **alternative hypothesis** $H_1$ (or\n$H_a$). They are set up **before** seeing the data and justified by\nprevious research.\n\n-   Given two categorical variables $X$ and $Y$, we assume under $H_0$\n    that both variables are independent from each other. This hypothesis\n    describes the \"default state of the world\"\n    [@james_introduction_2021: 555], i.e., what we would usually expect\n    to see. There is no association between the variables of interest\n    and, therefore, no effect.\n\n-   By contrast, the alternative hypothesis $H_1$ claims that $X$ and\n    $Y$ are **not** independent, i.e., that $H_0$ does not hold. $X$ and\n    $Y$ then appear to be correlated in some way, i.e., there is some\n    kind of effect.\n\nIn the subsequent sections, we will consider two scenarios, one for\ncategorical and one for continuous data:\n\n1.  **Categorical variables**: We are interested in finding out whether\n    English clause `ORDER` ('sc-mc' or 'mc-sc') depends on the type of\n    the subordinate clause (`SUBORDTYPE`), which can be either temporal\n    ('temp') or causal ('caus').\n\nOur hypotheses are:\n\n-   $H_0:$ The variables `ORDER` and `SUBORDTYPE` are independent.\n\n-   $H_1:$ The variables `ORDER` and `SUBORDTYPE` are **not**\n    independent.\n\n::: {.callout-note title=\"What does independence really mean?\" collapse=\"true\"}\nThe core idea is \"that the probability distribution of the response\nvariable is the same for each group\"\n[@agrestiFoundationsStatisticsData2022: 177]. If clause `ORDER` is the\nresponse variable and `SUBORDTYPE` the explanatory variable,\nindependence would mean that the outcomes of the response variable\n`ORDER = \"mc-sc\"` and `ORDER = \"sc-mc\"` are equally likely to occur in\nthe groups `SUBORDTYPE = \"temp\"` **and** `SUBORDTYPE = \"caus\"`.\n\nThe term **probability distribution** refers to a mathematical function\nthat assigns probabilities to the outcomes of a variable. If we consider\ntwo variables at the same time, such as $X$ and $Y$, they are said to have **marginal probability functions** $f_1(x)$ and $f_2(y)$. If we condition the outcomes of all values on each other, the following equivalence will hold:\n\n$$\nf(x \\mid y) = f_1(x) \\text{ and } f(y \\mid x) = f_2(y).\n$$ {#eq-indep}\n\nThus, the null hypothesis assumes that the probabilities of each combination of values (such as `ORDER` and `SUBORDTYPE`), denoted by $\\pi_{ij}$, have the relationship in @eq-indep. This can be stated succinctly as\n\n$$\nH_0 : \\pi_{ij} = P(X = i)P(Y = j).\n$$ {#eq-nullhyp-math}\n\n:::\n\n2.  **Continuous variables**: As part of a phonetic study, we compare\n    the base frequencies of the F1 formants (in Hz) for male and female\n    speakers of Apache. We forward the following hypotheses:\n\n-   $H_0:$ mean `F1 frequency` of men $=$ mean `F1 frequency` of women.\n\n-   $H_1:$ mean `F1 frequency` of men $\\ne$ mean `F1 frequency` of\n    women.\n\nBased on our data, we can decide to either **accept** or **reject**\n$H_0$. Rejecting $H_0$ can be viewed as evidence in favour of $H_1$ and\nthus marks a potential 'discovery' in the data.\n\n::: {.callout-caution title=\"Hypothesis testing -- what could go wrong?\"}\nThere is always a chance that we accept or reject the wrong hypothesis;\nthe four possible constellations are summarised in the table below [cf.\n@heumann_introduction_2022: 223]:\n\n|                           | $H_0$ is true                                       | $H_0$ is not true                                   |\n|-------------------|---------------------------|---------------------------|\n| $H_0$ **is not rejected** | $\\color{green}{\\text{Correct decision}}$            | $\\color{red}{\\text{Type II } (\\beta)\\text{-error}}$ |\n| $H_0$ **is rejected**     | $\\color{red}{\\text{Type I } (\\alpha)\\text{-error}}$ | $\\color{green}{\\text{Correct decision}}$            |\n\nThe probability of a Type I error, which refers to the rejection of\n$H_0$ although it is true, is called the **significance level**\n$\\alpha$, which has a conventional value of $0.05$ (i.e., a 5% chance of\ncommitting a Type I error). Nevertheless, it is always recommended to\nexplicitly state the $\\alpha$-level used for rejecting/accepting $H_0$.\n:::\n\n## Constructing the critical region\n\nAn important question remains: How great should the difference be for us\nto reject $H_0$? The $p$-value measures **the probability of\nencountering a specific value of a test statistic** ($\\chi^2$-score,\n$t$, $F$ etc.) on the condition that $H_0$ is true.\n\n::: callout-note\n## A more precise definition of $p$-values\n\n\"The $P$-value is the probability, presuming that $H_0$ is true, that\nthe test statistic equals the observed value or a value even more\nextreme in the direction predicted by $H_a$\n[@agrestiFoundationsStatisticsData2022: 163]\".\n:::\n\nFor example, a $p$-value of $0.02$ means that we would see a particular\ntest statistic only 2% of the time if $X$ and $Y$ were unrelated (or if\nthere was no difference between $\\bar{x}$ and $\\bar{y}$, respectively).\nSince our significance level $\\alpha$ is set to $0.05$, we only reject\nthe null hypothesis if this conditional probability is lower than 5%.\n\nWe obtain $p$-values by consulting the probability density functions of\nthe underlying sampling distributions:\n\n-   Probability density function for the $\\chi^2$-distribution with\n    $df = 1$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Generate random samples from a chi-squared distribution with 1 degree of freedom\nx <- rchisq(100000, df = 1)\n\n# Create histogram\nhist(x,\n     breaks = \"Scott\",\n     freq = FALSE,\n     xlim = c(0, 20),\n     ylim = c(0, 0.2),\n     ylab = \"Probability density of observing a specific score\",\n     xlab = \"Chi-squared score\",\n     main = \"Histogram for a chi-squared distribution with 1 degree of freedom (df)\",\n     cex.main = 0.9)\n\n# Overlay PDF\ncurve(dchisq(x, df = 1), from = 0, to = 150, n = 5000, col = \"steelblue\", lwd = 2, add = TRUE)\n```\n\n::: {.cell-output-display}\n![](Hypothesis_testing_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n-   Probability density function for the $t$-distribution with\n    $df = 112.19$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Given t-statistic and degrees of freedom\nt_statistic <- 2.4416\ndf <- 112.19\n\n# Generate random samples from a t-distribution with the given degrees of freedom\nx <- rt(100000, df = df)\n\n# Create histogram\nhist(x,\n     breaks = \"Scott\",\n     freq = FALSE,\n     xlim = c(-5, 5),\n     ylim = c(0, 0.4),\n     ylab = \"Probability density of observing a specific score\",\n     xlab = \"t-score\",\n     main = \"Histogram for a t-distribution with 112.19 degrees of freedom\",\n     cex.main = 0.9)\n\n# Overlay PDF\ncurve(dt(x, df = df), from = -5, to = 5, n = 5000, col = \"steelblue\", lwd = 2, add = TRUE)\n```\n\n::: {.cell-output-display}\n![](Hypothesis_testing_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n",
    "supporting": [
      "Hypothesis_testing_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}