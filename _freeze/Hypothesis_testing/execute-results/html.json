{
  "hash": "eba457712cf151329d7d7bd94b0dd10d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hypothesis testing\"\nauthor:\n  name: \"Vladimir Buskin\" \n  orcid: \"0009-0005-5824-1012\"\n  affiliation: \n    name: \"Catholic University of EichstÃ¤tt-Ingolstadt\"\n    department: \"English Language and Linguistics\"\nformat:\n  html:\n    self-contained: true\n    code-fold: false\n    theme: default\n    toc: true\n    toc-depth: 4\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 3\n    scrollable: true\neditor: visual\nbibliography: R.bib\n---\n\n\n## Suggested reading\n\nFor linguists:\n\n> @gries_statistics_2021: Chapter 1.3.2\n\nGeneral:\n\n> @baguleySeriousStatsGuide2012: Chapter 4\n>\n> @agrestiFoundationsStatisticsData2022: Chapter 5\n\n## Hypothesis testing {#sec-hyp}\n\nThe null hypothesis significance testing (NHST) framework offers\nresearchers a convenient way of testing theoretical assumptions about a\npopulation of interest. This chiefly involves setting up a set of\nfalsifiable statistical hypotheses, gathering evidence from the observed\ndata and computing the (in)famous '$p$-value' to determine \"statistical\nsignificance\" -- a notion that is frequently misinterpreted in\nscientific studies\n\nThis involves setting up a set of falsifiable statistical hypotheses\nthat predict the presence or absence of certain patterns in the data.\nThese are known as the **null hypothesis** and the **alternative\nhypothesis**. They are set up **before** seeing the data and justified\nby previous research. Association tests have the following components:\n\n-   The **null hypothesis** $H_0$ could be viewed describing the\n    \"default state of the world\" [@james_introduction_2021: 555], which\n    suggests that there is no noteworthy effect to be observed. If we\n    are interested in some property $\\theta$ of the population (also\n    known as a **population parameter**) (e.g., frequency differences\n    between observed or expected counts; differences in mean reaction\n    times between groups etc.), then it would have the value 0 under\n    $H_0$.\n\n-   The **alternative hypothesis** $H_1$ (or $H_a$) plainly states that\n    the null hypothesis is false: There is an effect, i.e.,\n    $H_1: \\theta \\neq 0$. The parameter thus takes values in an\n    alternative range.\n\n-   In the NHST approach, researchers typically seek evidence against\n    $H_0$. To quantify the amount of evidence the observed data\n    provides, specific **test statistics** are computed depending on the\n    data type at hand; for instance, $\\chi^2$ ('chi-squared') is typical\n    for discrete and $t$ for continuous data.\n\n-   The final rejection of $H_0$ is determined by the **significance\n    probability** $p$, which denotes the probability that \"the test\n    statistic equals the observed value or a value even more extreme in\n    the direction predicted by $H_a$\"\n    [@agrestiFoundationsStatisticsData2022: 163]\", assuming $H_0$ is\n    true.\n\n    -   If $p$ is lower than a pre-defined threshold (typically 0.05),\n        also known as the **significance level** $\\alpha$, we reject\n        $H_0$. However, if $p \\geq$ 0.05, this **neither justifies\n        rejecting nor accepting** the null hypothesis\n        [@baguleySeriousStatsGuide2012: 121].\n\n    -   For example, a $p$-value of $0.02$ means that we would see a\n        particular test statistic, which often reflect usage patterns in\n        linguistic data, only 2% of the time if $X$ and $Y$ were\n        unrelated (i.e., if $H_0$ were true). Since $0.02$ lies below\n        our significance level $\\alpha$ = $0.05$, this would suggest a\n        statistically significant relationship between $X$ and $Y$, and\n        we could therefore reject $H_0$.\n\n### Some examples of hypotheses\n\n**Categorical variables**: We are interested in finding out whether\nEnglish clause `ORDER` ('sc-mc' or 'mc-sc') depends on the type of the\nsubordinate clause (`SUBORDTYPE`), which can be either temporal ('temp')\nor causal ('caus').\n\nOur hypotheses are:\n\n-   $H_0:$ The variables `ORDER` and `SUBORDTYPE` are independent.\n\n-   $H_1:$ The variables `ORDER` and `SUBORDTYPE` are **not**\n    independent.\n\n**Continuous variables**: As part of a phonetic study, we compare the\nbase frequencies of the F1 formants of vowels (in Hz) for male and\nfemale speakers of Apache. We forward the following hypotheses:\n\n-   $H_0:$ mean `F1 frequency` of men $=$ mean `F1 frequency` of women.\n\n-   $H_1:$ mean `F1 frequency` of men $\\ne$ mean `F1 frequency` of\n    women.\n\n### Hypothesis testing -- what could go wrong?\n\nThere is always a chance that we accept or reject the wrong hypothesis;\nthe four possible constellations are summarised in the table below [cf.\n@heumann_introduction_2022: 223]:\n\n|                           | $H_0$ is true                                       | $H_0$ is not true                                   |\n|-------------------|---------------------------|---------------------------|\n| $H_0$ **is not rejected** | $\\color{green}{\\text{Correct decision}}$            | $\\color{red}{\\text{Type II } (\\beta)\\text{-error}}$ |\n| $H_0$ **is rejected**     | $\\color{red}{\\text{Type I } (\\alpha)\\text{-error}}$ | $\\color{green}{\\text{Correct decision}}$            |\n\n### Advanced: Where does the $p$-value come from?\n\nLet's say that the statistical analysis of clause `ORDER` and\n`SUBORDTYPE` has returned a test statistic of $\\chi^2 = 6.5$ for 2 $df$.\nIn order to compute the probability $P(\\chi^2 \\geq 5)$, we need to\nconsult the **sampling distribution** of this test statistic. The\nsampling distribution is a probability distribution that assigns\nprobabilities to the values of a test statistic.\n\nThe probability density function $f(x)$ of the $\\chi^2$-distribution for\n2 degrees of freedom (abbreviated $df$ and affect the function's shape)\nis visualised below. The $p$-value corresponds to the green area under\ncurve ranging from $x = 6.5$ up to $\\infty$.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Hypothesis_testing_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nThe probability $P(\\chi^2 \\geq 6.5)$ can be obtained by integrating over\nall $\\chi^2$-values in the range $0 \\leq X < 6.5$ and subtracting them\nfrom 1, which represents the total area under the curve\n\n$$\nP(X\\geq 6.5) = 1 - \\int_{0}^{6.5} f(x) dx\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# For a chi-squared test statistic of 6.5 with 2 degree of freedom\np_value <- 1 - pchisq(6.5, df = 2)\n\nprint(p_value) # significant!\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.03877421\n```\n\n\n:::\n:::\n",
    "supporting": [
      "Hypothesis_testing_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}