{
  "hash": "c0fa12d524d260d09c3029eb57a8edd0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hypothesis testing\"\nauthor: Vladimir Buskin\nformat:\n  html:\n    self-contained: true\n    code-fold: false\n    theme: default\n    toc: true\n    toc-depth: 4\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 3\n    scrollable: true\neditor: visual\nbibliography: R.bib\n---\n\n\n## Suggested reading\n\nFor linguists:\n\n> @gries_statistics_2021: Chapter 1.3.2\n\nGeneral:\n\n> @baguleySeriousStatsGuide2012: Chapter 4\n>\n> @agrestiFoundationsStatisticsData2022: Chapter 5\n\n## Hypothesis testing {#sec-hyp}\n\nThe null hypothesis significance testing (NHST) framework offers\nresearchers a convenient way of testing theoretical assumptions about a\npopulation of interest (e.g., a speech community). This involves setting\nup a set of falsifiable statistical hypotheses that predict the presence\nor absence of certain patterns in the data. These are known as the\n**null hypothesis** $H_0$ and the **alternative hypothesis** $H_1$ (or\n$H_a$). They are set up **before** seeing the data and justified by\nprevious research.\n\n-   Given two categorical variables $X$ and $Y$, we assume under $H_0$\n    that both variables are independent from each other. This hypothesis\n    describes the \"default state of the world\"\n    [@james_introduction_2021: 555], i.e., what we would usually expect\n    to see. There is no association between the variables of interest\n    and, therefore, no effect.\n\n-   By contrast, the alternative hypothesis $H_1$ claims that $X$ and\n    $Y$ are **not** independent, i.e., that $H_0$ does not hold. $X$ and\n    $Y$ then appear to be correlated in some way, i.e., there is some\n    kind of effect.\n\nIn the subsequent sections, we will consider two scenarios:\n\n1.  We are interested in finding out whether English clause `ORDER`\n    ('sc-mc' or 'mc-sc') depends on the type of the subordinate clause\n    (`SUBORDTYPE`), which can be either temporal ('temp') or causal\n    ('caus').\n\nOur hypotheses are:\n\n-   $H_0:$ The variables `ORDER` and `SUBORDTYPE` are independent.\n\n-   $H_1:$ The variables `ORDER` and `SUBORDTYPE` are **not**\n    independent.\n\n2.  As part of a phonetic study, we compare the base frequencies of the\n    F1 formants for male and female speakers of Apache. We forward the\n    following hypotheses:\n\n-   $H_0:$ mean `F1 frequency` of men $=$ mean `F1 frequency` of women.\n\n-   $H_1:$ mean `F1 frequency` of men $\\ne$ mean `F1 frequency` of\n    women.\n\nBased on our data, we can decide to either **accept** or **reject**\n$H_0$. Rejecting $H_0$ can be viewed as evidence in favour of $H_1$ and\nthus marks a potential 'discovery' in the data. However, there is always\na chance that we accept or reject the wrong hypothesis; the four\npossible constellations are summarised in the table below [cf.\n@heumann_introduction_2022: 223]:\n\n|                           | $H_0$ is true                                       | $H_0$ is not true                                   |\n|-------------------|---------------------------|---------------------------|\n| $H_0$ **is not rejected** | $\\color{green}{\\text{Correct decision}}$            | $\\color{red}{\\text{Type II } (\\beta)\\text{-error}}$ |\n| $H_0$ **is rejected**     | $\\color{red}{\\text{Type I } (\\alpha)\\text{-error}}$ | $\\color{green}{\\text{Correct decision}}$            |\n\nThe probability of a Type I error, which refers to the rejection of\n$H_0$ although it is true, is called the **significance level**\n$\\alpha$, which has a conventional value of $0.05$ (i.e., a 5% chance of\ncommitting a Type I error). Nevertheless, it is always recommended to\nstate explicitly the $\\alpha$-level used for rejecting/accepting $H_0$.\n\n## Constructing the critical region\n\nAn important question remains: How great should the difference be for us\nto reject $H_0$? The $p$-value measures **the probability of\nencountering a specific value of a test statistic** ($\\chi^2$-score, $t$, $F$ etc.) on the condition that $H_0$ is true.\n\n::: callout-note\n## A more precise definition of $p$-values\n\n\"The $P$-value is the probability, presuming that $H_0$ is true, that\nthe test statistic equals the observed value or a value even more\nextreme in the direction predicted by $H_a$ [@agrestiFoundationsStatisticsData2022: 163]\".\n:::\n\nFor example, a $p$-value of $0.02$ means that we would see a particular\ntest statistic only 2% of the time if $X$ and $Y$\nwere unrelated (or if there was no difference between $\\bar{x}$ and\n$\\bar{y}$, respectively). Since our significance level $\\alpha$ is set\nto $0.05$, we only reject the null hypothesis if this conditional probability is lower than 5%.\n\nWe obtain $p$-values by consulting the probability density functions of\nthe underlying sampling distributions:\n\n-   Probability density function for the $\\chi^2$-distribution with\n    $df = 1$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Generate random samples from a chi-squared distribution with 1 degree of freedom\nx <- rchisq(100000, df = 1)\n\n# Create histogram\nhist(x,\n     breaks = \"Scott\",\n     freq = FALSE,\n     xlim = c(0, 20),\n     ylim = c(0, 0.2),\n     ylab = \"Probability density of observing a specific score\",\n     xlab = \"Chi-squared score\",\n     main = \"Histogram for a chi-squared distribution with 1 degree of freedom (df)\",\n     cex.main = 0.9)\n\n# Overlay PDF\ncurve(dchisq(x, df = 1), from = 0, to = 150, n = 5000, col = \"orange\", lwd = 2, add = TRUE)\n```\n\n::: {.cell-output-display}\n![](Hypothesis_testing_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n-   Probability density function for the $t$-distribution with\n    $df = 112.19$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Given t-statistic and degrees of freedom\nt_statistic <- 2.4416\ndf <- 112.19\n\n# Generate random samples from a t-distribution with the given degrees of freedom\nx <- rt(100000, df = df)\n\n# Create histogram\nhist(x,\n     breaks = \"Scott\",\n     freq = FALSE,\n     xlim = c(-5, 5),\n     ylim = c(0, 0.4),\n     ylab = \"Probability density of observing a specific score\",\n     xlab = \"t-score\",\n     main = \"Histogram for a t-distribution with 112.19 degrees of freedom\",\n     cex.main = 0.9)\n\n# Overlay PDF\ncurve(dt(x, df = df), from = -5, to = 5, n = 5000, col = \"orange\", lwd = 2, add = TRUE)\n```\n\n::: {.cell-output-display}\n![](Hypothesis_testing_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n",
    "supporting": [
      "Hypothesis_testing_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}