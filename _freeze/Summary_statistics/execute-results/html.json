{
  "hash": "e247948446b8321b6ddf8fce14801d76",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Summary statistics: Theory and practice\"\nauthor: Vladimir Buskin\nformat:\n  html:\n    self-contained: true\n    theme: default\n    toc: true\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 3\n    scrollable: true\neditor: visual\nbibliography: R.bib\n---\n\n\n\n\n## Measures of central tendency {.scrollable}\n\n\n::: {.cell}\n\n:::\n\n\n### The mean {.smaller .scrollable}\n\n-   A useful summary statistic is the arithmetic mean $\\bar{x}$ [cf.\n    @heumann_introduction_2022: 38]. Consider a variable $X$ with\n    observations $x_1, x_2, ..., x_n$ from a sample of size $n$. The\n    sample mean then corresponds to\n\n    $$\n    \\bar{x}= \\frac{x_1 + x_2 + ... + x_n}{n} \\\\ = \\frac{1}{n}\\sum_{i=1}^n{x_i}.\n    $$\n\nIn R, we can obtain the average value of a numeric vector with the\n`mean()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using mean()\nmean(cl.order$LEN_MC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.265509\n```\n\n\n:::\n\n```{.r .cell-code}\n# or by hand:\nmean <- 1/length(cl.order$LEN_MC) * sum(cl.order$LEN_MC)\n```\n:::\n\n\n**Visualisation**:\n\n::: panel-tabset\n#### Histogram\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\n# Plot distribution of LEN_MC\ncl.length.hist <- ggplot(cl.order, aes(x = LEN_MC)) +\n                  geom_histogram(binwidth = 2)\n\ncl.length.hist +\n  # Add mean\n  geom_vline(aes(xintercept = mean(LEN_MC)),\n             color = \"steelblue\",\n             linewidth = 1) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n#### Density plot\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\n# Plot distribution of LEN_MC\ncl.length.dens <- ggplot(cl.order, aes(x = LEN_MC)) +\n                  geom_density()\n\ncl.length.dens +\n  # Add mean\n  geom_vline(aes(xintercept = mean(LEN_MC)),\n             color = \"steelblue\",\n             linewidth = 1) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n:::\n\n### The median {.smaller}\n\n-   The `median()` function computes the \"the halfway point of the data\n    (50% of the data are above the median; 50% of the data are below\"\n    [@winter_statistics_2020: 58]\n\n    $$\n    \\begin{equation}\n    \\tilde{x}_{0.5} = \n    \\begin{cases}\n    x_{((n+1)/2)} & \\text{if } n \\text{ is odd.} \\\\\n    \\frac{1}{2}(x_{n/2}+x_{(n/2+1)}) & \\text{if } n \\text{ is even.}\n    \\end{cases} \n    \\end{equation}\n    $$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using median()\nmedian(cl.order$LEN_MC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8\n```\n\n\n:::\n\n```{.r .cell-code}\n# or by hand:\nsample_sorted <- sort(cl.order$LEN_MC) # sort values in ascending order\n\nn <- length(cl.order$LEN_MC) # sample size is 403 (odd number!)\n\nmedian <- sample_sorted[(n + 1) %/% 2] # compute median\n```\n:::\n\n\n**Visualisation**:\n\n::: panel-tabset\n#### Histogram\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl.length.hist +\n  # Add mean\n  geom_vline(aes(xintercept = mean(LEN_MC)), color = \"steelblue\", linewidth = 1) +\n  # Add median\n  geom_vline(aes(xintercept = median(LEN_MC)), color = \"red\", linewidth = 1) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n#### Density plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl.length.dens +\n  # Add mean\n  geom_vline(aes(xintercept = mean(LEN_MC)), color = \"steelblue\", linewidth = 1) +\n  # Add median\n  geom_vline(aes(xintercept = median(LEN_MC)), color = \"red\", linewidth = 1) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n:::\n\n### Sample variance and standard deviation {.smaller}\n\n-   In order to assess how well the mean represents the data, it is\n    instructive to compute the **variance** `var()` and the **standard\n    deviation** `sd()` for a sample.\n\n-   The sample variance is defined as\n\n$$s^2 = \\frac{1}{n}\\sum_{i=1}^n{(x_i - \\bar{x})^2}. $$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using var()\nvar(cl.order$LEN_MC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 25.12585\n```\n\n\n:::\n\n```{.r .cell-code}\n# or by hand:\n\nsample_data <- cl.order$LEN_MC\n\n# Calculate the sample standard deviation\n\nvar <- 1 / length(sample_data) * sum((sample_data - mean(sample_data))^2) # formula above\n\n# Note that R's var() function applies an additional bias correction measure:\n\nvar_corrected <- 1 / (length(sample_data) - 1) * sum((sample_data - mean(sample_data))^2) # equivalent to var()\n```\n:::\n\n\n-   Correspondingly, the standard deviation of the mean is the square\n    root of the variance [cf. @heumann_introduction_2022: 51-2]:\n\n$$ s = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n{(x_i - \\bar{x})^2}} $$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using sd()\nsd(cl.order$LEN_MC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.012569\n```\n\n\n:::\n\n```{.r .cell-code}\n# or by hand:\n\nsample_data <- cl.order$LEN_MC\n\n# Calculate the sample standard deviation\n\nsd <- sqrt(1 / (length(sample_data) - 1)* sum((sample_data - mean(sample_data))^2))\n```\n:::\n\n\n**Application and visualisation**:\n\n::: panel-tabset\n#### Example 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl.length.hist +\n  # Add verticle line for the mean\n  geom_vline(aes(xintercept = mean(LEN_MC)), color = \"steelblue\", linewidth = 1) +\n  # Add -1sd\n  geom_vline(aes(xintercept = mean(LEN_MC) - sd(LEN_MC)), color = \"orange\", linewidth = 1) +\n  # Add +1sd\n  geom_vline(aes(xintercept = mean(LEN_MC) + sd(LEN_MC)), color = \"orange\", linewidth = 1) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n#### Example 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create data frame with mean and sd for each clause ORDER\n\ncl.order %>% \n  # Select variables of interest\n  select(ORDER, LEN_MC) %>% \n  # Group results of following operations by ORDER\n  group_by(ORDER) %>% \n    # Create grouped summary of mean and sd for each ORDER\n    summarise(mean = mean(LEN_MC),\n                sd = sd(LEN_MC)) -> cl_mean_sd; cl_mean_sd\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  ORDER  mean    sd\n  <chr> <dbl> <dbl>\n1 mc-sc  9.04  4.91\n2 sc-mc  9.75  5.22\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot results \n\nggplot(cl_mean_sd, aes(x = ORDER, y = mean)) +\n  # Barplot with a specific variable mapped onto y-axis\n  geom_col() +\n  # Add mean and standard deviation to the plot\n  geom_errorbar(aes(x = ORDER,\n                    ymin = mean-sd,\n                    ymax = mean+sd), width = .2) +\n  theme_classic() +\n  labs(y = \"Mean length of main clauses\", x = \"Clause order\")\n```\n\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n:::\n\n### Quantiles\n\n-   While `median()` divides the data into two equal sets (i.e., two 50%\n    quantiles), the `quantile()` function makes it possible to partition\n    the data further.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    quantile(cl.order$LEN_MC)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n      0%  25%  50%  75% 100% \n       2    6    8   11   31 \n    ```\n    \n    \n    :::\n    :::\n\n\n-   `quantile(x, 0)` and `quantile(x, 1)` thus show the minimum and\n    maximum values, respectively.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    quantile(cl.order$LEN_MC, 0)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    0% \n     2 \n    ```\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    quantile(cl.order$LEN_MC, 1)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    100% \n      31 \n    ```\n    \n    \n    :::\n    :::\n\n\n### Quartiles and boxplots\n\n![The structure of the boxplot [@wickham_r_2023: Chapter\n2.3.1]](images/Screenshot%202023-10-19%20at%2018.50.20.png)\n\n-   Consider the distribution of clause length by clause order:\n\n::: panel-tabset\n#### Version 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cl.order, aes(x = ORDER, y = LEN_MC)) +\n  geom_boxplot() +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n#### Version 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cl.order, aes(x = ORDER, y = LEN_MC)) +\n  geom_boxplot() +\n  geom_jitter() + # add data points \n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n:::\n\n-   Compare it to the corresponding rotated density plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(cl.order, aes(x = LEN_MC, fill = ORDER)) +\n  geom_density(alpha = 0.5) +\n  coord_flip() +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n## Theoretical distributions\n\n### The normal distribution\n\nA great number of numerical variables in the world follow the well-known\n**normal** (or Gaussian) **distribution**, which includes test scores,\nweight and height, among many others.\n\nIf a random variable $X$ is normally distributed, it is determined by\nthe parameters $\\mu$ (the mean) and $\\sigma$ (the standard deviation).\nFormally, we can summarise this using the notation\n\n$$ X \\sim N(\\mu, \\sigma^2).$$ The **probability density function (PDF)**\nof the normal distribution has a characteristic bell-shape. The density\nvalues on the $y$-axis indicate the likelihood of encountering a\nspecific value of $X$ [cf. @winter_statistics_2020: 56;\n@heumann_introduction_2022: 173-177].\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n### Bernoulli distribution\n\nThe **Bernoulli distribution** is a discrete probability distribution\nfor random variables which have only two possible outcomes: \"positive\"\n(often coded as 1) and \"negative\" (often coded as 0). Examples of such\nvariables include coin tosses (heads/tails), binary response questions\n(yes/no), and defect status (defective/non-defective).\n\nIf a random variable $X$ follows a Bernoulli distribution, it is\ndetermined by the parameter $p$, which is the probability of the\npositive case:\n\n$$ X \\sim Bernoulli(p).$$ The **probability mass function (PMF)** of the\nBernoulli distribution is given by: $$\nP(X = x) = \n\\begin{cases} \np & \\text{if } x = 1 \\\\\n1 - p & \\text{if } x = 0 \n\\end{cases}\n$$\n\nwhere $0 \\leq p \\leq 1$. This function shows the probability of $X$\ntaking on the value of 1 or 0 [cf. @heumann_introduction_2022: 162-163].\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Summary_statistics_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n::: callout-note\n\n### Extensions\n\nA Bernoulli experiment presupposes a single trial (e.g., tossing a coin\nonce). If we are interested in the distribution of a binary discrete\nvariable over $n$ Bernoulli trials, we can describe it in terms of the\n**binomial distribution** [@heumann_introduction_2022: 163-166].\n\nCategorical variables with more than 2 outcomes and $n$ Bernoulli trials\ncan be modelled using the **multinomial distribution**\n[@heumann_introduction_2022: 167-169].\n:::\n\n",
    "supporting": [
      "Summary_statistics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}