{
  "hash": "04367c8d441057712bf20360c97d0da7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Ordinal regression\"\nauthor:\n  name: \"Vladimir Buskin\" \n  orcid: \"0009-0005-5824-1012\"\n  affiliation: \n    name: \"Catholic University of EichstÃ¤tt-Ingolstadt\"\n    department: \"English Language and Linguistics\"\nformat:\n  html:\n    self-contained: true\n    logo: logo.png\n    footer: \"Regression\"\n    theme: Reference\n    toc: true\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 4\n    scrollable: true\neditor: visual\nbibliography: R.bib\n---\n\n\n## Suggested reading\n\nGeneral:\n\n> @baguleySeriousStatsGuide2012: Chapter 17.4.5\n>\n> @oconnellLogisticRegressionModels2006\n>\n> @powersStatisticalMethodsCategorical2008: Chapter 7\n>\n> [Documentation of Cumulative Link\n> Models](https://cran.r-project.org/web/packages/ordinal/vignettes/clm_article.pdf)\n\n## Introduction\n\nIn her recent contribution, @glassEnglishVerbsCan2021 examines possible\nreasons why certain transitive verbs have a stronger affinity towards\nobject omission compared to others, placing special emphasis on the\nroutinisation of the actions denoted by the verbs. Specifically, she\nassesses **how high/low-routine contexts affect the acceptability of\nobject omission** for transitive verbs from different frequency bins.\n\nWe will replicate her findings using her survey data\n`Glass_2021_survey_processed.csv`[^ordinal_regression-1]:\n\n[^ordinal_regression-1]: The original dataset can be retrieved from\n    Lelia Glass's OSF repository: <https://osf.io/t6zw5> \\[Last\n    accessed: 27th September, 2024\\].\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load libraries\nlibrary(tidyverse)\nlibrary(ordinal)\nlibrary(MASS)\nlibrary(sjPlot)\nlibrary(effects)\nlibrary(ggeffects)\nlibrary(ggpubr)\n\n# For additional tests\nlibrary(DescTools)\nlibrary(generalhoslem)\nlibrary(brant)\n\n# Load data\nsurvey <- read.csv(\"Glass_2021_survey_processed.csv\")\n\n# Inspect dataset\nstr(survey)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t784 obs. of  5 variables:\n $ rating       : int  3 4 3 3 2 4 3 2 3 2 ...\n $ freq         : chr  \"hi\" \"lo\" \"lo\" \"hi\" ...\n $ verb         : chr  \"pick\" \"catch\" \"throw\" \"break\" ...\n $ ParticipantID: chr  \"Participant1\" \"Participant1\" \"Participant1\" \"Participant1\" ...\n $ routine      : chr  \"hi\" \"lo\" \"lo\" \"lo\" ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(survey)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  rating freq   verb ParticipantID routine\n1      3   hi   pick  Participant1      hi\n2      4   lo  catch  Participant1      lo\n3      3   lo  throw  Participant1      lo\n4      3   hi  break  Participant1      lo\n5      2   hi  taste  Participant1      hi\n6      4   hi bottle  Participant1      hi\n```\n\n\n:::\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Short breakdown of the variables\"}\n-   `routine`: In Glass's study, transitive verbs were randomly assigned\n    to one of the following conditions:\n\n> -   (High routine condition:) I worked at my poultry farm. Just like I\n>     always do, I **butchered** some chickens. Then I gathered some\n>     eggs.\n>\n> -   (Low-routine condition:) I visited a friend's job. Just because\n>     people wanted me to try it, I **butchered** some chickens. Then I\n>     went for a walk.\n>\n> Cf. Glass [-@glassEnglishVerbsCan2021: 66]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(survey$routine)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"hi\" \"lo\"\n```\n\n\n:::\n:::\n\n\n-   `rating` records the responses of participants to a follow-up\n    question regarding the acceptability of object omission. The answers\n    are recorded on a 1-5 Likert scale.\n\n> *The next time Caroline talks about butchering chickens the day\n> before, how likely do you think she is to say the following?*\n>\n> 'I **butchered** yesterday'\n>\n> Cf. Glass [-@glassEnglishVerbsCan2021: 66]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(survey$rating)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3 4 2 5 1\n```\n\n\n:::\n:::\n\n\n-   `verb` contains the items to be rated for the conditions in\n    `routine`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(survey$verb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"pick\"   \"catch\"  \"throw\"  \"break\"  \"taste\"  \"bottle\" \"sell\"   \"chop\"  \n```\n\n\n:::\n:::\n\n\n-   `frequency` relates to the frequency bins of the verbs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(survey$freq)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"hi\" \"lo\"\n```\n\n\n:::\n:::\n\n\n-   `ParticipantID` identifies each of the 98 subjects who provided\n    ratings\n:::\n\n## Descriptive overview\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nggplot(survey, aes(x = rating, fill = freq)) +\n  geom_density(alpha = 0.7) +\n  facet_wrap(~freq) +\n  theme_minimal() +\n  labs(title = \"Density of Ratings by Frequency\",\n       x = \"Rating\", y = \"Density\", fill = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nggplot(survey, aes(x = rating, fill = routine)) +\n  geom_density(alpha = 0.7) +\n  facet_wrap(~routine) +\n  theme_minimal() +\n  labs(title = \"Density of Ratings by Routine\",\n       x = \"Rating\", y = \"Density\", fill = \"Routine\")\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nlibrary(ggridges)\nggplot(survey, aes(x = rating, y = verb, fill = verb)) +\n  geom_density_ridges(scale = 5, rel_min_height = 0.01, alpha = 0.6) +\n  theme_ridges() +\n  #theme(legend.position = \"none\") +\n  labs(title = \"Distribution of Ratings by Verb\",\n       x = \"Rating\", y = \"Verb\")\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n## Modelling ordinal data\n\nOur task is clear: We need to measure how `routine` and `freq` affect\nthe variability in the acceptability ratings, while controlling for\nrepeated measurements for `verb` and `ParticipantID`, which impose a\nhierarchical structure on the dataset.\n\nFormally speaking, we have $p$ explanatory variables\n$X_1, X_2, ..., X_p$ for $1, ..., p$. The target variable, i.e. our $Y$,\nis `rating` with the ordered, discrete outcomes\n$y \\in \\{1, 2, 3, 4, 5\\}$.\n\nThe goal is to find a model $f$ that describes the relationship between\n$Y$ and $X_p$ as accurately as possible and minimises the error term\n$\\epsilon$:\n\n$$\nY = f(X_1, X_2, ..., X_p) + \\epsilon\n$$ {#eq-mod}\n\n### Ordered logistic regression\n\nOne family of models that respects the ordered, yet categorical nature\nof $Y$ is **ordered** (or ordinal) **logistic regression**. Other terms\ninclude **proportional odds models** and **cumulative logit/link\nmodels**.\n\n::: {.callout-note collapse=\"true\" title=\"Recap: Logistic regression\"}\nLogistic regression is used to model categorical response variables with\ntwo or more levels. For instance, let's assume our $Y$ is dichotomous\nwith the following two outcomes:\n\n$$\nY =\n\\begin{cases}\n\\text{yes} \\\\\n\\text{no}\n\\end{cases}\n$$ {#eq-logreg-outcomes}\n\nUsing the logistic function, we can estimate the probability of one\noutcome versus the other **given** the predictors $X_p$. Their\nlog-transformed odds ratio (**log odds**) is equivalent of the\nall-too-familiar linear model:\n\n$$\n\\log\\left(\\frac{P(Y = yes \\mid X_1, X_2, ..., X_p)}{1 - P(Y = yes \\mid X_1, X_2, ..., X_p)}\\right) = \\beta_0 + \\sum_{i=1}^p \\beta_iX_i\n$$ {#eq-logreg}\n:::\n\nCore to this approach is the notion of **cumulative probabilities**. Let\n$J$ denote the number of ordered categories in $Y$. In Glass's case\nstudy, the estimated cumulative probabilities for each ordered outcome\n(= acceptability rating) would have the forms in @eq-cumprobs.\n\n$$\n\\begin{array}{rcl}\nP(Y \\leq 1) & = & P(Y = 1) \\\\\nP(Y \\leq 2) & = & P(Y = 1) + P(Y = 2) \\\\\nP(Y \\leq 3) & = & P(Y = 1) + P(Y = 2) + P(Y = 3) \\\\\n& \\vdots & \\\\\nP(Y \\leq j) & = & P_1 + ... + P_j\n\\end{array}\n$$ {#eq-cumprobs}\n\nWe can now update our logistic regression model to take into account\ncumulative probabilities for $j = 1, ..., J-1$.\n\n$$\n\\log\\left(\\frac{P(Y \\leq j \\mid X_1, X_2, ..., X_p)}{1 - P(Y \\leq j \\mid X_1, X_2, ..., X_p)}\\right) = \\beta_0 + \\sum_{i=1}^p \\beta_iX_i\n$$ {#eq-cumlog}\n\nThe intercepts $\\beta_{0_j}$ serve as **cutpoints** between the adjacent\nordinal categories. For $J = 5$ categories, there are $J - 1 = 4$\ncutpoints, i.e.,\n\n-   1\\|2 for $P(Y \\leq 1)$\n\n-   2\\|3 for $P(Y \\leq 2)$\n\n-   3\\|4 for $P(Y \\leq 3)$\n\n-   4\\|5 for $P(Y \\leq 4)$.\n\nGiven a change in predictor values, the slope coefficients $\\beta_pX_p$\nindicate how the probability of being in a higher rating category\nchanges [@baguleySeriousStatsGuide2012: 691--2].\n\nWe can obtain \"regular\" probabilities from the cumulative ones by\ndrawing on the equivalence in @eq-cumprobs-transform.\n\n$$\nP(Y = j) = P(Y \\leq j) - P(Y \\leq j - 1)\n$$ {#eq-cumprobs-transform}\n\nFor instance, the probability $P(Y = 3)$ is equivalent to\n\n$$\nP(Y = 3) = P(Y \\leq 3) - P(Y \\leq 2).\n$$ {#eq-example}\n\n::: {.callout-important title=\"Assumptions of proportional odds models\" collapse=\"false\"}\n**The proportional odds assumption** stipulates a stable effect of the\npredictors on the (log) odds of the ordinal outcomes across all possible\ncutpoints [@oconnellLogisticRegressionModels2006: 29]. In case of\nviolation, it is better to rely on partial proportional odds models or\nmultinomial logistic regression instead.\n:::\n\n## Application in R\n\nThere are several R packages that support ordinal logistic regression\nmodels. This section provides an overview of some of the more common (as\nwell as well-documented) implementations.\n\n### Using `polr()` from the `MASS` library\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert to factor and determine ordering\nsurvey$rating <- factor(survey$rating, ordered = TRUE, levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\n# Fit polr model\nsurvey.polr <- polr(rating ~ \n                      freq +\n                      routine,\n                      data = survey)\n\n# Model summary\nsummary(survey.polr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\npolr(formula = rating ~ freq + routine, data = survey)\n\nCoefficients:\n             Value Std. Error  t value\nfreqlo    -0.01095     0.1291 -0.08483\nroutinelo -0.55521     0.1302 -4.26449\n\nIntercepts:\n    Value   Std. Error t value\n1|2 -0.8704  0.1228    -7.0859\n2|3  0.1342  0.1188     1.1290\n3|4  1.2528  0.1293     9.6856\n4|5  2.8915  0.2003    14.4345\n\nResidual Deviance: 2246.662 \nAIC: 2258.662 \n```\n\n\n:::\n\n```{.r .cell-code}\n# R-squared and AIC\nPseudoR2(survey.polr, c(\"Nagelkerke\", \"AIC\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Nagelkerke          AIC \n   0.0244793 2258.6617419 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(survey.polr, show.se = TRUE, show.aic = TRUE, show.dev = TRUE, transform = NULL)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"4\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">rating</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Log-Odds</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Error</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">1|2</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.87</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.11&nbsp;&ndash;&nbsp;-0.63</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">2|3</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.10&nbsp;&ndash;&nbsp;0.37</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.259</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">3|4</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.00&nbsp;&ndash;&nbsp;1.51</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">4|5</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.89</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.20</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.50&nbsp;&ndash;&nbsp;3.28</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">freq [lo]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.01</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.26&nbsp;&ndash;&nbsp;0.24</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.932</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">routine [lo]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.56</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.81&nbsp;&ndash;&nbsp;-0.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"4\">784</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Nagelkerke</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.024</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Deviance</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">2246.662</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">AIC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">2258.662</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n::: {.callout-tip title=\"Interpreting the model parameters\" collapse=\"true\"}\n-   **Coefficients**: The conditions `freqlo` (low frequency) and\n    `routinelo` (low-routine context) both have negative values, which\n    means that both of them decrease the probability of obtaining a\n    higher acceptability rating (compared to `freqhi` and `routinehi`).\n\n-   **Intercepts**: These represent the cutpoints between the ordinal\n    categories, which are necessary for calculating the probabilities of\n    each ordinal category.\n:::\n\n### Testing assumptions and goodness of fit\n\n-   Test proportional odds assumption:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrant(survey.polr) # p < 0.05 is a violation of the assumption\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n-------------------------------------------- \nTest for\tX2\tdf\tprobability \n-------------------------------------------- \nOmnibus\t\t14.45\t6\t0.02\nfreqlo\t\t6.5\t3\t0.09\nroutinelo\t8.14\t3\t0.04\n-------------------------------------------- \n\nH0: Parallel Regression Assumption holds\n```\n\n\n:::\n:::\n\n\n-   Hosmer-Lemeshow test, which is essentially a $\\chi^2$-test:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogitgof(survey$rating, # observed\n         fitted(survey.polr), # expected\n         ord = TRUE) # respect ordering\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tHosmer and Lemeshow test (ordinal model)\n\ndata:  survey$rating, fitted(survey.polr)\nX-squared = 51.173, df = 35, p-value = 0.03808\n```\n\n\n:::\n:::\n\n\n-   The Lipsitz test is an extension of the Hosmer-Lemeshow test. Note\n    that it requires the response to be a factor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlipsitz.test(survey.polr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLipsitz goodness of fit test for ordinal response models\n\ndata:  formula:  rating ~ freq + routine\nLR statistic = 20.261, df = 9, p-value = 0.01637\n```\n\n\n:::\n:::\n\n\n-   Part of the same family of tests is the Pulkstenis-Robinson test,\n    which also relies on the $\\chi^2$-distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npulkrob.chisq(survey.polr, catvars = c(\"freq\", \"routine\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPulkstenis-Robinson chi-squared test\n\ndata:  formula:  rating ~ freq + routine\nX-squared = 21.476, df = 9, p-value = 0.0107\n```\n\n\n:::\n:::\n\n\n### Visualisation\n\n#### With `effects`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Routine effect plot\nplot(Effect(focal.predictors = c(\"routine\"), mod = survey.polr), rug = FALSE, style=\"stacked\")\n```\n:::\n\n\n#### With `ggeffects` and `ggplot2`\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# Get the ggeffects data\neff <- ggeffects::ggeffect(survey.polr, \"freq\")\n\n# Convert to a data frame\nplot_data <- as.data.frame(eff)\n\n# Ensure the response.level has the desired levels\nplot_data$response.level <- factor(plot_data$response.level, \n                                   levels = c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\"),\n                                   labels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\n# Create the plot with confidence intervals\np1 <- ggplot(plot_data, aes(x = x, y = predicted, color = response.level, group = response.level)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.1, linewidth = 0.5) +\n  scale_color_viridis_d() +\n  labs(\n    x = \"Frequency\",\n    y = \"Predicted Probability\",\n    color = \"Rating\"\n  ) +\n  facet_grid(~ response.level) +\n  theme_minimal() +\n  theme(\n    legend.position = \"right\",\n    panel.grid.minor = element_blank(),\n    axis.title = element_text(face = \"bold\"),\n    plot.title = element_text(face = \"bold\"),\n    plot.subtitle = element_text(margin = margin(b = 10))\n  ) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1))\n\np1\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# Get the ggeffects data for \"routine\"\neff_routine <- ggeffects::ggeffect(survey.polr, \"routine\")\n\n# Convert to a data frame\nplot_data_routine <- as.data.frame(eff_routine)\n\n# Ensure the response.level has the desired levels for \"routine\"\nplot_data_routine$response.level <- factor(plot_data_routine$response.level, \n                                           levels = c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\"),\n                                           labels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\n# Create the second plot for \"routine\"\np2 <- ggplot(plot_data_routine, aes(x = x, y = predicted, color = response.level, group = response.level)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.1, linewidth = 0.5) +\n  scale_color_viridis_d() +\n  labs(\n    x = \"Routine\",\n    y = \"Predicted Probability\",\n    color = \"Rating\"\n  ) +\n  facet_grid(~ response.level) +\n  theme_minimal() +\n  theme(\n    legend.position = \"right\",\n    panel.grid.minor = element_blank(),\n    axis.title = element_text(face = \"bold\"),\n    plot.title = element_text(face = \"bold\"),\n    plot.subtitle = element_text(margin = margin(b = 10))\n  ) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1))\n\np2\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# Generate the interaction effects for \"freq\" and \"routine\"\neff_interaction <- ggeffect(survey.polr, terms = c(\"freq\", \"routine\"))\n\n# Convert to a data frame\nplot_data_interaction <- as.data.frame(eff_interaction)\n\n# Ensure the response.level has the desired levels\nplot_data_interaction$response.level <- factor(plot_data_interaction$response.level, \n                                               levels = c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\"),\n                                               labels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\n\n# Create the interaction plot with facet by 'x' and color by 'response.level'\np_interaction <- ggplot(plot_data_interaction, aes(x = group, y = predicted, color = response.level, group = response.level)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.1, linewidth = 0.5) +\n  scale_color_viridis_d() +\n  labs(\n    title = \"Predicted Probabilities for Interaction of Frequency and Routine\",\n    x = \"Routine\",\n    y = \"Predicted Probability\",\n    color = \"Rating\"\n  ) +\n  facet_wrap(~ x, labeller = labeller(x = c(\"hi\" = \"High Frequency\", \"lo\" = \"Low Frequency\"))) +  # Facet by \"freq\"\n  theme_minimal() +\n  theme(\n    legend.position = \"right\",\n    panel.grid.minor = element_blank(),\n    axis.title = element_text(face = \"bold\"),\n    plot.title = element_text(face = \"bold\"),\n    plot.subtitle = element_text(margin = margin(b = 10))\n  ) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1))\n\n# Display the interaction plot\np_interaction\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n### Using `clm()` from the `ordinal` library\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert to factor and determine ordering\nsurvey$rating <- factor(survey$rating, ordered = TRUE, levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\n# Fit cumulative link model\nclm.1 <- ordinal::clm(rating ~ \n                    freq +\n                    routine,\n                    data = survey, Hess=TRUE)\n\n# Model summary\nsummary(clm.1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(clm.1, show.se = TRUE, show.aic = TRUE, show.dev = TRUE, transform = NULL)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"4\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">rating</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Log-Odds</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Error</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">1|2</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.87</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.11&nbsp;&ndash;&nbsp;-0.63</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">2|3</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.12</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.10&nbsp;&ndash;&nbsp;0.37</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.259</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">3|4</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.25</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.00&nbsp;&ndash;&nbsp;1.51</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">4|5</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.89</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.20</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">2.50&nbsp;&ndash;&nbsp;3.28</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">freq [lo]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.01</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.26&nbsp;&ndash;&nbsp;0.24</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.932</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">routine [lo]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.56</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.13</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.81&nbsp;&ndash;&nbsp;-0.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"4\">784</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">R<sup>2</sup> Nagelkerke</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.024</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">AIC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">2258.662</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n\n### Mixed-effects ordinal regression\n\n::: {.callout-note collapse=\"true\" title=\"Recap: Mixed-effects models\"}\nIf the data is nested according to some grouping factor with $1, ..., k$\ngroups, we can let the intercept and/or slopes vary by group. For\ninstance, recall the varying-intercept model:\n\n$$\nY = \\alpha_{k} + \\beta_1X_{1} + \\beta_2X_{2} + ... + \\epsilon \\qquad \\alpha_{k} \\sim N(\\mu_{\\alpha}, \\sigma_{\\alpha}^2).\n$$ In this case we also speak of **random effects**.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert to factor and determine ordering\nsurvey$rating <- factor(survey$rating, ordered = TRUE, levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\n# Fit mixed model with random intercepts for \"verb\" and \"ParticipantID\"\nclm.2 <- ordinal::clmm(rating ~ \n                    freq * routine +\n                    (1 | verb) +\n                    (1 | ParticipantID),\n                    data = survey, Hess=TRUE)\n\n# Model summary\nsummary(clm.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: rating ~ freq * routine + (1 | verb) + (1 | ParticipantID)\ndata:    survey\n\n link  threshold nobs logLik  AIC     niter     max.grad cond.H \n logit flexible  784  -991.65 2001.30 598(2386) 3.81e-04 1.5e+02\n\nRandom effects:\n Groups        Name        Variance Std.Dev.\n ParticipantID (Intercept) 2.0628   1.4363  \n verb          (Intercept) 0.9059   0.9518  \nNumber of groups:  ParticipantID 98,  verb 8 \n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)    \nfreqlo            -0.1567     0.2138  -0.733 0.463437    \nroutinelo         -0.7473     0.2103  -3.553 0.000381 ***\nfreqlo:routinelo  -0.1406     0.2981  -0.472 0.637046    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -1.3562     0.4020  -3.374\n2|3   0.2062     0.3988   0.517\n3|4   1.8329     0.4053   4.523\n4|5   3.8639     0.4401   8.780\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(clm.2, show.se = TRUE, show.aic = TRUE, show.dev = TRUE, transform = NULL)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table style=\"border-collapse:collapse; border:none;\">\n<tr>\n<th style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; \">&nbsp;</th>\n<th colspan=\"4\" style=\"border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; \">rating</th>\n</tr>\n<tr>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; \">Predictors</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">Log-Odds</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">std. Error</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">CI</td>\n<td style=\" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  \">p</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">1|2</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.36</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.40</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;2.14&nbsp;&ndash;&nbsp;-0.57</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">2|3</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.21</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.40</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.58&nbsp;&ndash;&nbsp;0.99</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.605</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">3|4</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.83</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.41</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">1.04&nbsp;&ndash;&nbsp;2.63</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">4|5</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.86</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.44</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">3.00&nbsp;&ndash;&nbsp;4.73</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">freq [lo]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.16</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.21</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.58&nbsp;&ndash;&nbsp;0.26</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.463</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">routine [lo]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.75</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.21</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;1.16&nbsp;&ndash;&nbsp;-0.34</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \"><strong>&lt;0.001</strong></td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; \">freq [lo] Ã routine [lo]</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.14</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.30</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">&#45;0.72&nbsp;&ndash;&nbsp;0.44</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  \">0.637</td>\n</tr>\n<tr>\n<td colspan=\"5\" style=\"font-weight:bold; text-align:left; padding-top:.8em;\">Random Effects</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&sigma;<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">3.29</td>\n</tr>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>ParticipantID</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">2.06</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">&tau;<sub>00</sub> <sub>verb</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.91</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">ICC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.47</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>verb</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">8</td>\n\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">N <sub>ParticipantID</sub></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">98</td>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;\">Observations</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;\" colspan=\"4\">784</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">Marginal R<sup>2</sup> / Conditional R<sup>2</sup></td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">0.028 / 0.489</td>\n</tr>\n<tr>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;\">AIC</td>\n<td style=\" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;\" colspan=\"4\">2001.305</td>\n</tr>\n\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# Extract random effects\nre_verb <- ranef(clm.2)$verb\nre_participant <- ranef(clm.2)$ParticipantID\n\n# Create dataframes for random effects\ndf_verb <- data.frame(verb = rownames(re_verb), re = re_verb[,1])\ndf_participant <- data.frame(ParticipantID = rownames(re_participant), re = re_participant[,1])\n\n# Get predictions for an average case\npred_avg <- ggpredict(clm.2, terms = c(\"freq\", \"routine\"))\n\n# Add random effects to predictions\npred_verb <- crossing(pred_avg, df_verb) %>%\n  mutate(predicted = predicted + re)\n\npred_participant <- crossing(pred_avg, df_participant) %>%\n  mutate(predicted = predicted + re)\n\n# Create a horizontal dot plot for random effects of participants\np_caterpillar <- ggplot(df_participant, aes(x = re, y = reorder(ParticipantID, re))) +\n  geom_point(size = 3, color = \"steelblue3\") +  # Dots representing the random effects\n  labs(title = \"Random Effects for Participants\", \n       x = \"Random Effect Estimate (log odds)\", \n       y = \"Participant ID\") +\n   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey20\") +\n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank())  # Removes the gridlines for y-axis\n\np_caterpillar2 <- ggplot(df_verb, aes(x = re, y = reorder(verb, re))) +\n  geom_point(size = 3, color = \"steelblue3\") +  # Dots representing the random effects\n  labs(title = \"Random Effects for Verbs\", \n       x = \"Random Effect Estimate (log odds)\", \n       y = \"Verb\") +\n   geom_vline(xintercept = 0, linetype = \"dashed\", color = \"grey20\") +\n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank())  # Removes the gridlines for y-axis\n\nggarrange(p_caterpillar, p_caterpillar2, ncol = 2, common.legend = TRUE, legend = \"right\")\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Generalised Additive Mixed-effects Models (GAMMs)\n\n### Suggested reading\n\nFor linguists:\n\n> Baayen & Linke [-@baayenGeneralizedAdditiveMixed2020]\n\nGeneral:\n\n> Hastie & Tibshirani [-@hastieGeneralizedAdditiveModels1991]\n>\n> Wood [-@woodGeneralizedAdditiveModels2006]\n\n### Rationale\n\nA core assumption of Generalised Linear Models (GLMs) is a linear\nrelationship between predictor(s) and response. If, however, one is\ninterested in exploring potential non-linear trends without the risk of\nextreme overfitting, GAMs offer an elegant solution: Instead of relying\non the linear sum of model coefficients, GAMs estimate more flexible\n**smooth terms** $f_k$ for $k = 1, ..., p$. For illustration, @eq-gam\nshows a linear additive model for a continuous target variable with $p$\npredictors.\n\n$$\nY = \\beta_0 + \\sum\\limits_{k = 1}^p f_k(X_k)\n$$ {#eq-gam}\n\n### Application in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load libraries\nlibrary(mgcv)\nlibrary(itsadug)\nlibrary(gratia)\n\n# Convert predictors to factors\nsurvey$ParticipantID <- as.factor(survey$ParticipantID)\nsurvey$verb <- as.factor(survey$verb)\n\n# Fit GAMM\ngam1 <- bam(as.numeric(rating) ~ # treated as numeric term\n              freq + # linear term\n              routine + # linear term\n              s(ParticipantID, bs = \"re\") + # smooth term\n              s(verb, bs = \"re\"), # smooth term\n              data = survey, \n              family = ocat(R = 5) # number of ordinal categories\n            )\n\n# Model summary\nsummary(gam1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFamily: Ordered Categorical(-1,0.51,2.09,4.06) \nLink function: identity \n\nFormula:\nas.numeric(rating) ~ freq + routine + s(ParticipantID, bs = \"re\") + \n    s(verb, bs = \"re\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   0.3613     0.3880   0.931    0.352    \nfreqlo       -0.2195     0.1431  -1.534    0.125    \nroutinelo    -0.7752     0.1428  -5.430 7.79e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                    edf Ref.df      F p-value    \ns(ParticipantID) 77.654     97  4.677  <2e-16 ***\ns(verb)           6.728      7 25.860  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nDeviance explained = 27.3%\nfREML =   1631  Scale est. = 1         n = 784\n```\n\n\n:::\n\n```{.r .cell-code}\n# Extract the intercepts for plotting\nthresh <- gratia::theta(gam1) %>% \n  tibble::as_tibble() %>% \n  setNames(c(\"threshold\"))\n\n# Extract predictions for \"routine\"\nroutine_pred <- ggpredict(gam1, terms = \"routine\")\n\n# Plot predictions\nroutine_pred %>% \n  ggplot(aes(x = x, y = predicted)) +\n  geom_point(col = \"steelblue\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high, width = 0), col = \"steelblue\") +\n  geom_hline(data = thresh, aes(yintercept = threshold), linetype = \"dashed\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Extract random effects for \"verb\"\nverb_pred <- ggpredict(gam1, terms = \"verb\")\n\n# Plot random effect\nverb_pred %>% \n  ggplot(aes(x = x, y = predicted)) +\n  geom_point(col = \"steelblue\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high, width = 0), col = \"steelblue\") +\n  geom_hline(data = thresh, aes(yintercept = threshold), linetype = \"dashed\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-24-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Extract random effects for \"ParticipantID\"\nsubj_pred <- ggpredict(gam1, terms = \"ParticipantID\")\n\n# Plot random effect\nsubj_pred |>\n  ggplot(aes(x = x, y = predicted)) +\n  geom_point(col = \"steelblue\") +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high, width = 0), col = \"steelblue\") +\n  #geom_line() +\n  geom_hline(data = thresh, aes(yintercept = threshold), linetype = \"dashed\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-24-3.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Ordinal_regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}