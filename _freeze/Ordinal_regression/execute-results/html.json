{
  "hash": "289f735527081a94281aa464def4800a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Ordinal regression\"\nauthor: Vladimir Buskin\nformat:\n  html:\n    self-contained: false\n    logo: logo.png\n    footer: \"Regression\"\n    theme: Reference\n    toc: true\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 4\n    scrollable: true\neditor: visual\nbibliography: R.bib\n---\n\n\n## Suggested reading\n\n> @powersStatisticalMethodsCategorical2008: Chapter 7\n> @baguleySeriousStatsGuide2012: Chapter 17.4.5\n\n## Introduction\n\nIn her recent contribution, @glassEnglishVerbsCan2021 examines possible\nreasons why certain transitive verbs have a stronger affinity towards\nobject omission compared to others, placing special emphasis on the\nroutinisation of the actions denoted by transitive verbs.\n\n### Research question and hypotheses\n\nHow do high/low-routine contexts affect the acceptability of object\nomission for transitive verbs of varying frequency of occurrence?\n\n**Low-frequency verbs**:\n\n-   $H_0:$ Mean Likert rating in low-routine contexts (low freq) $=$\n    Mean Likert rating in high-routine contexts (low freq)\n\n-   $H_1:$ Mean Likert rating in low-routine contexts (low freq) $\\neq$\n    Mean Likert rating in high-routine contexts (low freq)\n\n**High-frequency verbs**:\n\n-   $H_0:$ Mean Likert rating in low-routine contexts (high freq) = Mean\n    Likert rating in high-routine contexts (high freq)\n\n-   $H_1:$ Mean Likert rating in low-routine contexts (high freq) $\\neq$\n    Mean Likert rating in high-routine contexts (high freq)\n\n### Preparation\n\nLoad the data `Glass_2021_survey_processed.csv`[^ordinal_regression-1]:\n\n[^ordinal_regression-1]: The original dataset can be retrieved from\n    Lelia Glass's OSF repository: <https://osf.io/t6zw5> \\[Last\n    accessed: 27th September, 2024\\].\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ordinal)\n\n\nsurvey <- read.csv(\"Glass_2021_survey_processed.csv\")\n\nstr(survey)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t784 obs. of  5 variables:\n $ rating       : int  3 4 3 3 2 4 3 2 3 2 ...\n $ freq         : chr  \"hi\" \"lo\" \"lo\" \"hi\" ...\n $ verb         : chr  \"pick\" \"catch\" \"throw\" \"break\" ...\n $ ParticipantID: chr  \"Participant1\" \"Participant1\" \"Participant1\" \"Participant1\" ...\n $ routine      : chr  \"hi\" \"lo\" \"lo\" \"lo\" ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(survey)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  rating freq   verb ParticipantID routine\n1      3   hi   pick  Participant1      hi\n2      4   lo  catch  Participant1      lo\n3      3   lo  throw  Participant1      lo\n4      3   hi  break  Participant1      lo\n5      2   hi  taste  Participant1      hi\n6      4   hi bottle  Participant1      hi\n```\n\n\n:::\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Short breakdown of the variables\"}\n-   `routine`: In Glass's study, transitive verbs were randomly assigned\n    to one of the following conditions:\n\n> -   (High routine condition:) I worked at my poultry farm. Just like I\n>     always do, I butchered some chickens. Then I gathered some eggs.\n>\n> -   (Low-routine condition:) I visited a friend's job. Just because\n>     people wanted me to try it, I butchered some chickens. Then I went\n>     for a walk.\n>\n> Cf. Glass [-@glassEnglishVerbsCan2021: 66]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(survey$routine)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"hi\" \"lo\"\n```\n\n\n:::\n:::\n\n\n-   `rating` records the responses of participants to a follow-up\n    question regarding the acceptability of object omission. The answers\n    are recorded on a 1-5 Likert scale.\n\n> *The next time Caroline talks about butchering chickens the day\n> before, how likely do you think she is to say the following?*\n>\n> 'I butchered yesterday'\n>\n> Cf. Glass [-@glassEnglishVerbsCan2021: 66]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(survey$rating)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3 4 2 5 1\n```\n\n\n:::\n:::\n\n\n-   `verb` contains the items to be rated for the conditions in\n    `routine`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(survey$verb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"pick\"   \"catch\"  \"throw\"  \"break\"  \"taste\"  \"bottle\" \"sell\"   \"chop\"  \n```\n\n\n:::\n:::\n\n\n-   `frequency` relates to the frequency bins of the verbs:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(survey$freq)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"hi\" \"lo\"\n```\n\n\n:::\n:::\n\n\n-   `ParticipantID` identifies each of the 98 subjects who provided\n    ratings\n:::\n\n## Modelling ordinal data\n\nIn order to answer our research question, we need to assess how the\nfeatures `freq` and `routine` affect the variability in the\nacceptability ratings. Furthermore, we'll need to control for `verb` and\n`ParticipantID`, which impose a hierarchical structure on our dataset.\n\nWe will denote these predictor variables $X_p$ where $p$ represents the\nnumber of predictors. The target variable `rating` is our $Y$, i.e., our\nresponse variable with the ordered, discrete outcomes\n$y \\in \\{1, 2, 3, 4, 5\\}$. Our goal is to find a model $f$ that\ndescribes the relationship between $Y$ and $X_p$ as accurately as\npossible and minimises the erorr term $\\epsilon$:\n\n$$\nY = f(X_1, X_2, ..., X_p) + \\epsilon\n$$\n\n### Ordered logistic regression\n\nOne family of models that respects the ordered, yet categorical nature\nof $Y$ is ordered (or ordinal) logistic regression. Other terms include\n**proportional odds models**, **cumulative logit/link models** etc.\n\n::: {.callout-note collapse=\"true\" title=\"Recap: Logistic regression\"}\nLogistic regression is used to model categorical response variables with\ntwo or more levels. For instance, let's assume our $Y$ is dichotomous\nwith the following two outcomes:\n\n$$\nY =\n\\begin{cases}\n\\text{yes} \\\\\n\\text{no}\n\\end{cases}\n$$\n\nUsing the logistic function, we can estimate the probability of one\noutcome versus the other **given** the predictors $X_p$. Their\nlog-transformed odds ratio (**log odds**) is equivalent of the\nall-too-familiar linear model:\n\n$$\n\\log\\left(\\frac{P(Y = yes \\mid X_p)}{1 - P(Y = yes \\mid X_p)}\\right) = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p.\n$$\n:::\n\n::: {.callout-note collapse=\"true\" title=\"Recap: Mixed-effects models\"}\nCertain datasets display a nested (or hierarchical) structure; this\nbecomes particularly apparent in the case of multiple observations.\n\n(Add violation of independence)\n:::\n\nCore to this approach is the notion of **cumulative probabilities**. Let\n$J$ denote the number of ordered categories in $Y$. In Glass's case\nstudy ($J = 5$), the estimated cumulative probabilities for each ordered\noutcome would have the following form:\n\n$$\n\\begin{array}{rcl}\nP(Y \\leq 1) & = & P(Y = 1) \\\\\nP(Y \\leq 2) & = & P(Y = 1) + P(Y = 2) \\\\\nP(Y \\leq 3) & = & P(Y = 1) + P(Y = 2) + P(Y = 3) \\\\\nP(Y \\leq 4) & = & P(Y = 1) + P(Y = 2) + P(Y = 3) + P(Y = 4) \\\\\nP(Y \\leq 5) & = & P(Y = 1) + P(Y = 2) + P(Y = 3) + P(Y = 4) + P(Y = 5)\n\\end{array}\n$$ We can generalise this pattern to\n\n$$\nP(Y \\leq j) = \\hat{P_1} + ... + \\hat{P_j}\n$$\n\nWe can now update our logistic regression equation to take into account\ncumulative probabilities:\n\n$$\n\\log\\left(\\frac{P(Y \\leq j \\mid X_p)}{1 - P(Y \\leq j \\mid X_p)}\\right) = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p \\qquad j = 1, ..., J-1\n$$\n\n### Application in R\n\n### Using `polr()` from the `MASS` library\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nsurvey$rating <- factor(survey$rating, ordered = TRUE, levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\nsurvey.polr <- polr(rating ~ \n                      freq +\n                      routine,\n                      data = survey)\n\nsummary(survey.polr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\npolr(formula = rating ~ freq + routine, data = survey)\n\nCoefficients:\n             Value Std. Error  t value\nfreqlo    -0.01095     0.1291 -0.08483\nroutinelo -0.55521     0.1302 -4.26449\n\nIntercepts:\n    Value   Std. Error t value\n1|2 -0.8704  0.1228    -7.0859\n2|3  0.1342  0.1188     1.1290\n3|4  1.2528  0.1293     9.6856\n4|5  2.8915  0.2003    14.4345\n\nResidual Deviance: 2246.662 \nAIC: 2258.662 \n```\n\n\n:::\n\n```{.r .cell-code}\n## Get diagnostics\nlibrary(DescTools)\nPseudoR2(survey.polr, c(\"Nagelkerke\", \"AIC\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Nagelkerke          AIC \n   0.0244793 2258.6617419 \n```\n\n\n:::\n\n```{.r .cell-code}\n## Goodness-of-fit tests\nlibrary(generalhoslem)\nlipsitz.test(survey.polr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLipsitz goodness of fit test for ordinal response models\n\ndata:  formula:  rating ~ freq + routine\nLR statistic = 20.261, df = 9, p-value = 0.01637\n```\n\n\n:::\n\n```{.r .cell-code}\npulkrob.chisq(survey.polr, catvars = c(\"freq\", \"routine\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPulkstenis-Robinson chi-squared test\n\ndata:  formula:  rating ~ freq + routine\nX-squared = 21.476, df = 9, p-value = 0.0107\n```\n\n\n:::\n\n```{.r .cell-code}\n## Test proportional odds assumption\nlibrary(brant)\nbrant(survey.polr) # p < 0.05 is a violation of the assumption\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n-------------------------------------------- \nTest for\tX2\tdf\tprobability \n-------------------------------------------- \nOmnibus\t\t14.45\t6\t0.02\nfreqlo\t\t6.5\t3\t0.09\nroutinelo\t8.14\t3\t0.04\n-------------------------------------------- \n\nH0: Parallel Regression Assumption holds\n```\n\n\n:::\n\n```{.r .cell-code}\n## Plot (best so far)\nlibrary(effects)\nlibrary(ggeffects)\n\n## Frequency effect plot\nplot(Effect(focal.predictors = c(\"freq\"), mod = survey.polr), rug = FALSE, style = \"stacked\")\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Routine effect plot\nplot(Effect(focal.predictors = c(\"routine\"), mod = survey.polr), rug = FALSE, style=\"stacked\")\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n```{.r .cell-code}\n## Interaction\nplot(Effect(focal.predictors = c(\"routine\", \"freq\"), mod = survey.polr), rug = FALSE,\n     style=\"stacked\")\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-6-3.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggpubr)\nggarrange(p1, p2, ncol = 2, common.legend = TRUE, legend = \"right\")\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n### Using `clm()` from the `ordinal` library\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert to factors\nsurvey$rating <- factor(survey$rating, ordered = TRUE, levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n\nclm.1 <- ordinal::clm(rating ~ \n                    freq +\n                    routine,\n                    data = survey, Hess=TRUE)\n```\n:::\n\n\n\n### Mixed-effects\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvey$rating <- factor(survey$rating, ordered = TRUE, levels = c(\"1\", \"2\", \"3\", \"4\", \"5\"))\n#survey$verb <- factor(survey$verb)\n#survey$ParticipantID <- factor(survey$ParticipantID)\n#survey$routine <- factor(survey$routine)\n#survey$freq <- factor(survey$freq)\n\nclm.2 <- ordinal::clmm(rating ~ \n                    freq * routine +\n                    (1 | verb) +\n                    (1 | ParticipantID),\n                    data = survey, Hess=TRUE)\n\nsummary(clm.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: rating ~ freq * routine + (1 | verb) + (1 | ParticipantID)\ndata:    survey\n\n link  threshold nobs logLik  AIC     niter     max.grad cond.H \n logit flexible  784  -991.65 2001.30 598(2386) 3.81e-04 1.5e+02\n\nRandom effects:\n Groups        Name        Variance Std.Dev.\n ParticipantID (Intercept) 2.0628   1.4363  \n verb          (Intercept) 0.9059   0.9518  \nNumber of groups:  ParticipantID 98,  verb 8 \n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)    \nfreqlo            -0.1567     0.2138  -0.733 0.463437    \nroutinelo         -0.7473     0.2103  -3.553 0.000381 ***\nfreqlo:routinelo  -0.1406     0.2981  -0.472 0.637046    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -1.3562     0.4020  -3.374\n2|3   0.2062     0.3988   0.517\n3|4   1.8329     0.4053   4.523\n4|5   3.8639     0.4401   8.780\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggarrange(p_caterpillar, p_caterpillar2, ncol = 2, common.legend = TRUE, legend = \"right\")\n```\n\n::: {.cell-output-display}\n![](Ordinal_regression_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Ordinal_regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}