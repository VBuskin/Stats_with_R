{
  "hash": "81c38249e314ab7726842245114fdfab",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chi square test\"\nauthor: Vladimir Buskin\nformat:\n  html:\n    self-contained: true\n    code-fold: false\n    theme: default\n    toc: true\n    toc-depth: 4\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 3\n    scrollable: true\neditor: visual\nbibliography: R.bib\n---\n\n\n## Preparation\n\n\n\n\n\n-   Load packages:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"readxl\")\nlibrary(\"tidyverse\")\n```\n:::\n\n\n-   Load the data sets:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read_xlsx(\"Paquot_Larsson_2020_data.xlsx\")\n```\n:::\n\n\n### The $\\chi^2$-test\n\nThe next step is to compute a test statistic that indicates how strongly\nour data conforms to $H_0$. For instance, the Pearson $\\chi^2$ statistic\nis commonly used for categorical variables. It requires two types of\nvalues: the **observed frequencies** $n_{ij}$ in our data set and the\n**expected frequencies** $m_{ij}$, which we would expect to see if $H_0$\nwas true.\n\nThis table represents a generic contingency table where $X$ and $Y$ are\ncategorical variables. Each $x_i$ represents a category of $X$ and each\n$y_j$ represents a category of $Y$. In the table, each cell indicates\nthe count of observation $n_{ij}$ corresponding to the $i$-th row and\n$j$-th column.\n\n|     |       |          | $Y$      |     |          |     |\n|-----|-------|----------|----------|-----|----------|-----|\n|     |       | $y_1$    | $y_2$    | ... | $y_J$    |     |\n|     | $x_1$ | $n_{11}$ | $n_{12}$ | ... | $n_{1J}$ |     |\n|     | $x_2$ | $n_{21}$ | $n_{22}$ | ... | $n_{2J}$ |     |\n| $X$ | ...   | ...      | ...      | ... | ...      |     |\n|     | $x_I$ | $n_{I1}$ | $n_{I2}$ | ... | $n_{3J}$ |     |\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cross-tabulate the frequencies for the variables of interest\n\nfreqs <- table(data$ORDER, data$SUBORDTYPE); freqs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       \n        caus temp\n  mc-sc  184   91\n  sc-mc   15  113\n```\n\n\n:::\n:::\n\n\nWe calculate the expected frequencies by using the formula\n\n$$\nm_{ij} = \\frac{i\\textrm{th row sum} \\times j \\textrm{th column sum}}{\\textrm{number of observations}}.\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute expected frequencies\n\n## Calculate row totals\nrow_totals <- rowSums(freqs)\n\n## Calculate column totals\ncol_totals <- colSums(freqs)\n\n## Total number of observations\ntotal_obs <- sum(freqs)\n\n## Calculate expected frequencies\nexpected_table <- outer(row_totals, col_totals) / total_obs\n\nexpected_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           caus      temp\nmc-sc 135.79404 139.20596\nsc-mc  63.20596  64.79404\n```\n\n\n:::\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Definition of the $\\\\chi^2$-test\"}\nGiven a sample with $n$ observations and $k$ degrees of freedom\n($df$)[^hypothesis_testing-1], the $\\chi^2$-statistic measures how much\nthe observed frequencies **deviate** from the expected frequencies **for\neach cell** in a contingency table [cf. @heumann_introduction_2022:\n249-251]:\n\n$$\n\\chi^2 = \\sum_{i=1}^{I}\\sum_{i=j}^{J}{\\frac{(n_{ij} - m_{ij})^2}{m_{ij}}}.\n$$ The test stipulates that ...\n\n1.  all observations are independent of each other,\n2.  80% of the expected frequencies are $\\geq$ 5, and\n3.  all observed frequencies are $\\geq$ 1.\n:::\n\n[^hypothesis_testing-1]: The degrees of freedom are calculated by\n    $(\\textrm{number of rows} -1) \\times (\\textrm{number of columns} - 1)$.\n\n::: {.callout-tip collapse=\"true\" title=\"Implementation in R: Manual vs. automatic\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute chi-squared scores for all cells\n## Create empty chi_squared_table for later storage\nchi_squared_table <- matrix(NA, nrow = 2, ncol = 2,\n                            dimnames = list(c(\"mc-sc\", \"sc-mc\"), c(\"caus\", \"temp\")))\n\n# Loop: Repeat the following commands ...\nfor (i in 1:2) { # for each of the 2 rows and\n  for (j in 1:2) { # for each of the 2 columns:\n    observed_freq <- freqs[i, j] # 1. Get the observed frequencies\n    expected_freq <- expected_table[i, j] # 2. Get the expected frequencies\n    chi_squared_score <- ((observed_freq - expected_freq)^2) / expected_freq # 3. Compute chi-squared scores\n    chi_squared_table[i, j] <- chi_squared_score # 4. Store output in the chi_squared_table\n  }\n}\n\nchi_squared_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          caus     temp\nmc-sc 17.11278 16.69335\nsc-mc 36.76575 35.86463\n```\n\n\n:::\n:::\n\n\nOr, more elegantly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreqs_test <- chisq.test(freqs)\n\n# Expected frequencies\nfreqs_test$expected\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       \n             caus      temp\n  mc-sc 135.79404 139.20596\n  sc-mc  63.20596  64.79404\n```\n\n\n:::\n\n```{.r .cell-code}\n# Chi-squared scores\n(freqs_test$residuals)^2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       \n            caus     temp\n  mc-sc 17.11278 16.69335\n  sc-mc 36.76575 35.86463\n```\n\n\n:::\n\n```{.r .cell-code}\n# Test statistics\nfreqs_test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  freqs\nX-squared = 104.24, df = 1, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n:::\n\n::: callout-important\nIf the data does not meet the (expected) frequency requirements for the\n$\\chi^2$-test, the Fisher's Exact Test is a viable alternative (see\n`?fisher.test()` for details).\n:::\n\n## Workflow in R\n\n### $\\chi^2$-test\n\n#### Define hypotheses\n\n-   $H_0:$ The variables `ORDER` and `SUBORDTYPE` are independent.\n\n-   $H_1:$ The variables `ORDER` and `SUBORDTYPE` are **not**\n    independent.\n\n#### Descriptive overview\n\nWe plot the distribution of clause `ORDER` depending on `SUBORDTYPE`.\nThis requires (a) selecting the desired variables, (b) computing the\ntoken frequencies and (c) computing the percentages.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter data so as to show only those observations that are relevant\n\ndata %>% \n  # Filter columns\n  select(ORDER, SUBORDTYPE) %>%\n    # Count observations \n    count(ORDER, SUBORDTYPE) %>%  \n    # Compute percentages\n    mutate(pct = n/sum(n) * 100) -> data_order_subord\n\nknitr::kable(data_order_subord)\n```\n\n::: {.cell-output-display}\n\n\n|ORDER |SUBORDTYPE |   n|       pct|\n|:-----|:----------|---:|---------:|\n|mc-sc |caus       | 184| 45.657568|\n|mc-sc |temp       |  91| 22.580645|\n|sc-mc |caus       |  15|  3.722084|\n|sc-mc |temp       | 113| 28.039702|\n\n\n:::\n:::\n\n\nNext, we visualise the `ORDER` distribution using a barplot with a\ncustom y-axis, requiring `geom_col()`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Plot distribution\n\ndata_order_subord %>%\n  # Map variables onto axes\n  ggplot(aes(x = ORDER, y = pct, fill = SUBORDTYPE)) +\n    # Define plot type\n    geom_col(pos = \"dodge\") +\n    # Define theme\n    theme_classic()\n```\n\n::: {.cell-output-display}\n![](Chi_square_test_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n#### Running the test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cross-tabulate the frequencies for the variables of interest\n\nfreqs <- table(data$ORDER, data$SUBORDTYPE)\n\nfreqs ## Assumption met: all observed freqs => 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       \n        caus temp\n  mc-sc  184   91\n  sc-mc   15  113\n```\n\n\n:::\n\n```{.r .cell-code}\n# Run a chis-quared test on the absolute frequencies and print the results\n\ntest <- chisq.test(freqs, correct = FALSE)\n\n# Inspect expected frequencies\n\ntest$expected # Assumption met: all expected frequences => 5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       \n             caus      temp\n  mc-sc 135.79404 139.20596\n  sc-mc  63.20596  64.79404\n```\n\n\n:::\n:::\n\n\n#### Optional: Effect size\n\nThe sample-size independent effect size measure **Cramer's *V***\n($\\phi$) is defined as\n\n$$V = \\sqrt{\\frac{\\chi^2}{N \\times df}}.$$ The outcome varies between\n$0$ (= no correlation) and $1$ (= perfect correlation); cf. also Gries\n[-@gries_statistics_2013: 186].\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Compute Cramer's V\n\n## By hand:\n\n# Given chi-squared statistic\nchi_squared <- unname(test$statistic)\n\n# Total number of observations\ntotal_obs <- sum(freqs)\n\nsqrt(chi_squared / total_obs * (min(dim(freqs)) - 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5139168\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\n## Automatically:\nlibrary(\"confintr\") # Load library\n\ncramersv(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5139168\n```\n\n\n:::\n:::\n\n\n#### Reporting the results\n\nAccording to a $\\chi^2$-test, there is a significant association between\nclause `ORDER`and `SUBORDTYPE` at $p < 0.001$\n($\\chi^2 = 106.44, df = 1$), thus justifying the rejection of $H_0$.",
    "supporting": [
      "Chi_square_test_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}