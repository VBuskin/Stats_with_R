{
  "hash": "7eb31ffaaffd9722e53d761369a15eb6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regular expressions\"\nauthor: \n    - name: \"Vladimir Buskin\"\n      affiliations: \n        - \"Catholic University of Eichstätt-Ingolstadt\"\n      orcid: \"0009-0005-5824-1012\"\n    - name: \"Thomas Brunner\"\n      affiliations:\n        - \"Catholic University of Eichstätt-Ingolstadt\"\nformat:\n  html:\n    self-contained: true\n    theme: default\n    toc: true\n    number-sections: true\n    slide-number: true\n    incremental: false\n    slide-level: 3\n    scrollable: true\n    \neditor: visual\n---\n\n\n## Preparation\n\n::: callout-tip\n## Script\n\nYou can find the full R script associated with this unit\n[here](https://osf.io/uhdns).\n:::\n\n## Suggested reading\n\n> @lange_corpus_2020: Chapter 3.7\n>\n> [Detailed\n> cheatsheet](https://images.datacamp.com/image/upload/v1665049611/Marketing/Blog/Regular_Expressions_Cheat_Sheet.pdf)\n> (DataCamp)\n\n## Regular expressions\n\n**Regular expressions** (or 'regex') help us find more complex patterns\nin strings of text. Suppose we are interested in finding all\ninflectional forms of the lemma PROVIDE in a corpus, i.e., *provide,\nprovides, providing* and *provided*. Insteading of searching for all\nforms individually, we can construct a regular expression of the form\n\n$$\n\\text{provid(e(s)? | ing | ed)}\n$$ which can be read as\n\n> 'Match the sequence of letters \\<provid\\> as well as when it is\n> followed by the groups of letters \\<es\\> or \\<ing\\> or \\<ed\\>. Also\n> make the \\<s\\> in \\<es\\> optional.'\n\nNotice how optionality is signified by the `?` operator and alternatives\nby `|`.\n\nTo activate regular expression in a `kwic()` query, the `valuetype`\nargument has to be set to `\"regex\"`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load library and corpus\nlibrary(quanteda)\nICE_GB <- readRDS(\"ICE_GB.RDS\")\n\n# Perform query\nkwic_provide <- kwic(ICE_GB,\n                     \"provid(e(s)?|ing|ed)\",\n                     valuetype = \"regex\",\n                     window = 20)\n```\n:::\n\n\nThe number of hits has more than doubled. However, upon closer\ninspection, we'll notice a few false positives, namely *providential*,\n*provider* and *providers*:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(kwic_provide$keyword)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     provide     provided     Provided    Provident providential     provider \n         165          118            5            1            1            1 \n   providers     provides    providing    Providing \n           3           72           52            1 \n```\n\n\n:::\n:::\n\n\nThere are two ways to handle the output:\n\n1.  **Refine the search expression** further to only match those cases\n    of interest.\n2.  Manually **sort out irrelevant cases** during qualitative annotation\n    in a spreadsheet software.\n\nAs a rule of thumb, you should consider improving your search expression\nif you obtain hundreds or even thousands of false hits. Should there be\nonly few false positives, it's usually easier to simply mark them as\n\"irrelevant\" in your spreadsheet. A full workflow is demonstrated in\nunit [13. Data annotation](Annotation.qmd).\n\n## A RegEx Cheatsheet\n\n### Basic functions\n\n| **Command** | **Definition** | **Example** | **Finds**           |\n|-------------|----------------|-------------|---------------------|\n|             |                | `python`    | *python*            |\n| `.`         | Any character  | `.ython`    | *aython, bython...* |\n\n### Character classes and alternatives\n\n| **Command** | **Definition**                               | **Example**     | **Finds**                       |\n|-----------------|----------------------|-----------------|-----------------|\n| `[abc]`     | Class of characters                          | `[jp]ython`     | *jython, python*                |\n| `[^pP]`     | Excluded class of characters                 | `[^pP]ython`    | everything but *python, Python* |\n| `(...|...)` | Alternatives linked by logical operator `or` | `P(ython|eter)` | *Python, Peter*                 |\n\n### Quantifiers\n\n| **Command** | **Definition**                                | **Example**   | **Finds**                     |\n|-----------------|----------------------|-----------------|-----------------|\n| `?`         | One or zero instances of the preceding symbol | `Py?thon`     | *Python, Pthon*               |\n| `*`         | No matter how many times — also zero          | `Py*thon`     | *Python, Pthon, Pyyyython...* |\n|             |                                               | `P[Yy]*thon`  | *Python, Pthon, PyYYython...* |\n| `+`         | No matter how many times but at least once    | `Py+thon`     | *Python, Pyyython, Pyyyython* |\n| `{1,3}`     | `{min, max}`                                  | `Py{1,3}thon` | *Python, Pyython, Pyyython*   |\n\n### Pre-defined character classes\n\n::: callout-note\nThe double backslashes (`\\\\`) shown here are specific to the `quanteda`\nR package. In most other programming languages including Python, you\nonly need a single backslash (e.g., `\\w`, `\\d`, `\\s`). This\ndouble-escaping is an R-specific requirement due to how R handles string\nliterals.\n:::\n\n| **Command** | **Definition**                              | **Example**      | **Finds**                        |\n|-----------------|---------------------|-----------------|-----------------|\n| `\\\\w`       | All alphanumeric characters (A-Z, a-z, 0-9) | `\\\\w+ing`        | *walking*, *running*, *42ing*    |\n| `\\\\W`       | All non-alphanumeric characters             | `hello\\\\W+world` | *hello world*, *hello!!!world*   |\n| `\\\\d`       | All decimal numbers (0-9)                   | `\\\\d{3}-\\\\d{4}`  | *555-1234*, *867-5309*           |\n| `\\\\D`       | Everything which is not a decimal number    | `\\\\D+`           | *Hello!*, *Python_code*          |\n| `\\\\s`       | Empty space                                 | `word\\\\s+word`   | *word word*                      |\n| `\\\\b`       | Word boundary                               | `\\\\bpython\\\\b`   | Matches *python* as a whole word |\n\n## Querying parsed corpora\n\nThe range of linguistic patterns to be matched can be extended further\nif the corpus contains additional metadata, such as the part of speech\n(POS) of a token. POS-tagged corpora open up the option of looking for\nmore abstract patterns, such as all instances of the verb *eat* that are\nfollowed by a pronoun or noun:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load library and corpus\nICE_GB_POS <- readRDS(\"ICE_GB_POS.RDS\")\n\n# Perform query\nkwic_provide_POS2 <- kwic(ICE_GB_POS,\n                     phrase(\"\\\\b(ate|eat(s|ing|en)?)_VERB\\\\b _(PRON|NOUN)\"),\n                     valuetype = \"regex\",\n                     window = 5)\n\nhead(kwic_provide_POS2)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic\" style=\"font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> docname </th>\n   <th style=\"text-align:right;\"> from </th>\n   <th style=\"text-align:right;\"> to </th>\n   <th style=\"text-align:left;\"> pre </th>\n   <th style=\"text-align:left;\"> keyword </th>\n   <th style=\"text-align:left;\"> post </th>\n   <th style=\"text-align:left;\"> pattern </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> S1A-009.txt </td>\n   <td style=\"text-align:right;\"> 1198 </td>\n   <td style=\"text-align:right;\"> 1199 </td>\n   <td style=\"text-align:left;\"> I_PRON must_AUX &lt; , &gt; </td>\n   <td style=\"text-align:left;\"> eat_VERB them_PRON </td>\n   <td style=\"text-align:left;\"> &lt; ICE-GB:S1A-009 #71 : 1 </td>\n   <td style=\"text-align:left;\"> \\b(ate|eat(s|ing|en)?)_VERB\\b _(PRON|NOUN) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> S1A-010.txt </td>\n   <td style=\"text-align:right;\"> 958 </td>\n   <td style=\"text-align:right;\"> 959 </td>\n   <td style=\"text-align:left;\"> to &lt; , &gt; actually_ADV </td>\n   <td style=\"text-align:left;\"> eat_VERB it_PRON </td>\n   <td style=\"text-align:left;\"> for_ADP one_NOUN ' s_PART own_ADJ </td>\n   <td style=\"text-align:left;\"> \\b(ate|eat(s|ing|en)?)_VERB\\b _(PRON|NOUN) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> S1A-011.txt </td>\n   <td style=\"text-align:right;\"> 3245 </td>\n   <td style=\"text-align:right;\"> 3246 </td>\n   <td style=\"text-align:left;\"> : A &gt; I_PRON have_AUX </td>\n   <td style=\"text-align:left;\"> eaten_VERB my_PRON </td>\n   <td style=\"text-align:left;\"> way_NOUN round_ADP the_DET Yorkshire_PROPN Dales_PROPN </td>\n   <td style=\"text-align:left;\"> \\b(ate|eat(s|ing|en)?)_VERB\\b _(PRON|NOUN) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> S1A-011.txt </td>\n   <td style=\"text-align:right;\"> 4159 </td>\n   <td style=\"text-align:right;\"> 4160 </td>\n   <td style=\"text-align:left;\"> I_PRON ended_VERB up_ADP uhm_NOUN just_ADV </td>\n   <td style=\"text-align:left;\"> eating_VERB sort_NOUN </td>\n   <td style=\"text-align:left;\"> of_ADP_ADP lumps_NOUN of chicken_NOUN and_CCONJ </td>\n   <td style=\"text-align:left;\"> \\b(ate|eat(s|ing|en)?)_VERB\\b _(PRON|NOUN) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> S1A-018.txt </td>\n   <td style=\"text-align:right;\"> 455 </td>\n   <td style=\"text-align:right;\"> 456 </td>\n   <td style=\"text-align:left;\"> order_VERB on_ADPe_NUM first_ADJ and_CCONJ_CCONJ then_ADV_ADV </td>\n   <td style=\"text-align:left;\"> eat_VERB it_PRON </td>\n   <td style=\"text-align:left;\"> and then sort_ADV of_ADV carry_VERB </td>\n   <td style=\"text-align:left;\"> \\b(ate|eat(s|ing|en)?)_VERB\\b _(PRON|NOUN) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> S1A-019.txt </td>\n   <td style=\"text-align:right;\"> 1038 </td>\n   <td style=\"text-align:right;\"> 1039 </td>\n   <td style=\"text-align:left;\"> A &gt; and_CCONJ everybody_PRON was_AUX </td>\n   <td style=\"text-align:left;\"> eating_VERB something_PRON </td>\n   <td style=\"text-align:left;\"> &lt; ICE-GB:S1A-019 #76 : 1 </td>\n   <td style=\"text-align:left;\"> \\b(ate|eat(s|ing|en)?)_VERB\\b _(PRON|NOUN) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nOne R package that supplies functions for tokenisation, POS-tagging and\neven dependency parsing for dozens of languages is `udpipe`. They all\nrely on one common set of tags known as **Universal Dependencies**,\nwhich are listed here:\n\n::: {.callout-tip title=\"Universial dependencies -- Tagset\" collapse=\"true\"}\nCf. <https://universaldependencies.org/u/pos/>.\n\n| POS Tag | Description                                                                                               |\n|------------------|------------------------------------------------------|\n| ADJ     | Adjective: describes a noun (e.g., *big*, *old*, *green*, *first*)                                        |\n| ADP     | Adposition: prepositions and postpositions (e.g., *in*, *to*, *over*)                                     |\n| ADV     | Adverb: modifies verbs, adjectives, or other adverbs (e.g., *quickly*, *very*)                            |\n| AUX     | Auxiliary: helps form verb tenses, moods, or voices (e.g., *is*, *have*, *will*)                          |\n| CCONJ   | Coordinating conjunction: links words, phrases, or clauses (e.g., *and*, *or*, *but*)                     |\n| DET     | Determiner: introduces nouns (e.g., *the*, *a*, *some*, *my*)                                             |\n| INTJ    | Interjection: expresses emotion or reaction (e.g., *oh*, *wow*, *hello*)                                  |\n| NOUN    | Noun: person, place, thing, or concept (e.g., *cat*, *city*, *idea*)                                      |\n| NUM     | Numeral: expresses a number or ranking (e.g., *one*, *two*, *second*)                                     |\n| PART    | Particle: adds meaning without being an independent word class (e.g., *not*, *to* as in *to run*)         |\n| PRON    | Pronoun: replaces nouns (e.g., *he*, *she*, *they*, *it*)                                                 |\n| PROPN   | Proper noun: names specific entities (e.g., *London*, *Vladimir*)                                         |\n| PUNCT   | Punctuation: marks boundaries in text (*.* , *!* *?*)                                                     |\n| SCONJ   | Subordinating conjunction: links clauses, often indicating dependency (e.g., *if*, *because*, *although*) |\n| SYM     | Symbol: non-alphanumeric symbol (e.g., *%*, *&*, *\\#*)                                                    |\n| VERB    | Verb: action or state (e.g., *run*, *be*, *have*)                                                         |\n| X       | Other: used when a word doesn't fit into other categories                                                 |\n:::\n\n## Working with other corpora\n\nSome corpus platforms such as [BNCweb](https://bncweb.lancs.ac.uk),\n[CQPweb](https://cqpweb.lancs.ac.uk) or our local [KU\ncorpora](ku.de/corpora)[^regular_expressions-1] support a specialised\nquery syntax known as **CQP** (**C**orpus **Q**uery **P**rocessor),\nwhich enables users to query for strings with specific meta-attributes\n(text category, age, gender etc.).\n\n[^regular_expressions-1]: Note that the corpus platform of the Catholic\n    University of Eichstätt-Ingolstadt, which was set up by Dr. Thomas\n    Brunner, is only accessible to students or staff via the local\n    **eduroam** network or a **VPN client** which holds their\n    credentials.\n\n### Basic use\n\nOnce signed in on any of these platforms, the user interface will generally follow this layout:\n\n![CQP query of PROVIDE in the GloWbE corpus](CQP_example.png)\n\n-   To select a different corpus, navigate to `CQPweb main menu` under\n    **About CQPweb** in the left menu bar.\n\n-  To restrict search results to specific parts of the corpus, select `Restricted query` and choose the relevant text categories, varieties, etc.\n\nYou can now enter a search expression into the white box using the following pattern:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n[attribute = \"property\"]\n```\n:::\n\n\nFor example, to retrieve all inflectional forms of the verb\n*provide*, enter:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n[lemma = \"provide\"]\n```\n:::\n\n\nTo search for a word with a specific part-of-speech (POS) tag -- such as **like** used as a preposition -- use:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n[word = \"like\" & pos = \"ii\"]\n```\n:::\n\n\nFor a full list of POS-tags, refer to:\n\n-   [CLAWS5](https://ucrel.lancs.ac.uk/bnc2/bnc2guide.htm#tagset) (for **BNC**)\n-   [CLAWS7](https://ucrel.lancs.ac.uk/claws7tags.html) (for **COCA** and **GloWbE**)\n\n### Exporting and importing your results\n\nTo export your KWIC-hits, select `Download` in the top-right corner and\nspecify your output options (e.g., the size of the search window or the\nspeaker metadata). While you can immediately read the downloaded `concordance.txt` file into R,  it’s advisable to first perform some **manual clean-up** in spreadsheet software (e.g., MS Excel). This ensures all columns and rows are complete and properly formatted.\n\nTo do this in Excel: \n\n1.    Navigate to `File > Import > Text file`.\n\n2.    Select your file and choose `Delimited`.\n\n3.    Click Next, select `Tab` as the delimiter, then click `Next > Finish`.\n\n\nMake sure to **save your file**, ideally with the extension `.xlsx`.\n\nFrom here, please refer to the unit [Import/export data](Importing_exporting.qmd) for further steps.\n\n\n## Exercises\n\n::: callout-tip\n## Solutions\n\nYou can find the solutions to the exercises\n[here](https://osf.io/xaumr).\n:::\n\n::: {#exr-regex-1}\nHow could you refine the search expression for PROVIDE\n`\"provid(e(s)?|ing|ed)\"` to get rid of the irrelevant cases?\n:::\n\n::: {#exr-regex-2}\nWrite elegant regular expressions which find all inflectional forms of\nthe following verbs:\n\n-   *accept*\n\n-   *attach*\n\n-   *swim*\n\n-   *know*\n\n-   *forget*\n:::\n\n::: {#exr-regex-3}\nFind all nouns ending in *-er*.\n:::\n\n::: {#exr-regex-4}\nFind all four-digit numbers.\n:::\n\n::: {#exr-regex-5}\nFind all verbs that are followed by a preposition.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}