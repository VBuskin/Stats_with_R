---
title: "Logistic Regression"
author: Vladimir Buskin
format:
  html:
    self-contained: false
    logo: logo.png
    footer: "Regression"
    theme: Reference
    toc: true
    number-sections: true
    slide-number: true
    incremental: false
    slide-level: 4
    scrollable: true
editor: visual
bibliography: R.bib
---

## Recommended reading

Specifically for linguists:

> Levshina [-@levshina_how_2015: Chapter 12]
>
> Winter [-@winter_statistics_2020: Chapter 12]

Full theoretical treatment:

> James et al. [-@james_introduction_2021: Chapter 4]
>
> Hosmer & Lemeshow [-@hosmer_applied_2008].

## Preparation {.smaller}

Consider the data from Buskin's
[-@buskinDefiniteNullInstantiationfc][^logistic_regression-1]
corpus-study on subject pronoun realisation:

[^logistic_regression-1]: The input data is can be accessed via this OSF
    repository: <https://osf.io/qgnms>.

```{r, echo = TRUE, output = TRUE, eval = TRUE}
# Load libraries
library(tidyverse)
library(rms)
library(broom)
library(ggeffects)

# Load data
data_pro <- read.csv("INPUT_pronouns.csv", sep = ",", header = TRUE)
```

-   **Target variable**:

    -   `Reference` ('overt', 'null')

-   **Explanatory variables**:

    -   `Person` ('1.p.', '2.p', '3.p' as well as the dummy pronouns
        'it' and 'there')

    -   `Register` (the text category in the International Corpus of
        English; 'S1A' are informal conversations, whereas 'S1B'
        comprises formal class lessons)

    -   `Variety` (British English 'GB', Singapore English 'SING' and
        Hong Kong English 'HK') and

    -   `Referentiality` ('referential' with an identifiable referent or
        'non-referential' with no/generic reference)

```{r, echo = TRUE, output = TRUE, eval = TRUE}
head(data_pro)

table(data_pro$Reference)
```

### Descriptive overview

```{r, echo = FALSE, output = TRUE}
#| code-fold: true
#| code-summary: "Code"

library(ggpubr)

# Raw data for Ref x Reg x Var
data_pro %>% 
  count(Reference, Register, Variety) %>% 
  filter(Reference == "null") %>% 
  mutate(pct = n/sum(n) * 100) -> pro_stats1

# Raw data for Ref x Per x Var
data_pro %>% 
  count(Reference, Person, Variety) %>% 
  filter(Reference == "null") %>% 
  mutate(pct = n/sum(n) * 100) -> pro_stats2

# Raw data for Ref x Referent x Var
data_pro %>% 
  count(Reference, Referentiality, Variety) %>% 
  filter(Reference == "null") %>% 
  mutate(pct = n/sum(n) * 100) -> pro_stats3

# Plot 1
pro1 <- pro_stats1 %>%
  ggplot(aes(x = Variety, y = pct, color = Register)) +
  geom_point(size = 2) +
  theme_minimal() +
  labs(
    title = "Null subjects by Variety and Register",
    y = "Proportion of null subjects"
  )
  
# Plot 2
pro2 <- pro_stats2 %>%
  ggplot(aes(x = Variety, y = pct, color = Person)) +
  geom_point(size = 2) +
  theme_minimal() +
  labs(
    title = "Null subjects by Variety and Person",
    y = "Proportion of null subjects"
  )


# Plot 3
pro3 <- pro_stats3 %>%
  ggplot(aes(x = Variety, y = pct, color = Referentiality)) +
  geom_point(size = 2) +
  theme_minimal() +
  labs(
    title = "Null subjects by Variety and Referentiality",
    y = "Proportion of null subjects"
  )

ggarrange(pro1, pro2, pro3)
```

## Logistic regression

In contrast to linear regression, logistic regression models a
**qualitative response variable** $Y$ with two
outcomes[^logistic_regression-2]. In the present study, $Y$ is
pronominal `Reference` and has the outcomes `Reference = null` and
`Reference = overt`, which represent null and overt subjects,
respectively. Dichotomous variables of this kind are also often coded as
`yes`/`no` or `1`/`0`.

[^logistic_regression-2]: Logistic regression can also be used for
    $\geq 3$ classes by breaking down the response variable into a
    series of dichotomous variables. This is also known as **multinomial
    logistic regression** or **softmax regression.**

Another difference from linear regression is the **output** of the
model. In linear regression, we obtain a predicted value for the
continuous response variable we're interested in. For instance, if we're
modelling reaction times, the model will return an estimated reaction
time (given the predictors).

In logistic regression, however, we either get a **class label** or a
**probability**. When modelling pronominal reference, the model will
thus either tell us

1.  whether a speaker would use an overt or a null subject in a given
    observation (class prediction).

2.  what the probability of using one variant vs. the other would be
    (probability prediction).

A core component of logistic regression is the **logistic function**.
The rationale for using it is that the output of the function will
always lie between $0$ and $1$, and it will always denote a
**probability**.

```{r, echo = FALSE, output = TRUE}
#| code-fold: true
#| code-summary: "Code"

# Define the logistic function
logistic_function <- function(X, beta0, beta1) {
  exp(beta0 + beta1 * X) / (1 + exp(beta0 + beta1 * X))
}

# Parameters for the logistic function
beta0 <- 0   # Intercept
beta1 <- 1   # Slope

# Generate a sequence of X values
X_values <- seq(-10, 10, by = 0.1)

# Compute the corresponding p(X) values
p_values <- logistic_function(X_values, beta0, beta1)

# Create a data frame with the X and p(X) values
df <- data.frame(X = X_values, p = p_values)

# Plot the logistic function using ggplot2
ggplot(df, aes(x = X, y = p)) +
  geom_line(color = "black") +
  labs(title = "Logistic Function",
       x = "X",
       y = "P(Y = 1 | X)") +
  theme_minimal()

```

### The simple logistic model

Assuming a binary response variable $Y$ with the values 1 and 0 and a
single predictor $X$, we can model the probability $P(Y = 1 \mid X)$ as

$$
P(Y = 1 \mid  X) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}.
$$

The above expression is equivalent to

$$
\log\left(\frac{P(Y = 1 \mid  X)}{1 - P(Y = 1 \mid  X)}\right) = \beta_0 + \beta_1X.
$$

The fraction $\frac{P(Y = 1 \mid X)}{1-P(Y = 1 \mid X)}$ represents the
**odds**, which stand for to the probability of one outcome (e.g.,
`Reference = null`) compared to the other (e.g., `Reference = overt`).

Their logarithmic transformation are the **log odds** (or **logits**) of
one outcome versus the other.

::: {.callout-tip title="Understanding log odds"}
When interpreting the output of a logistic model, note that

-   positive log odds indicate an **increase** in
    $\frac{P(Y = 1 \mid X)}{1-P(Y = 1 \mid X)}$, whereas

-   negative log odds indicate a **decrease** in
    $\frac{P(Y = 1 \mid X)}{1-P(Y = 1 \mid X)}$.
:::

In more concrete terms: If $X = \text{Register}$, then our model would
have the form:

$$
\log\left(\frac{P(\text{Reference} = \text{null} \mid \text{Register})}{1- P(\text{Reference} = \text{null} \mid \text{Register})}\right) = \beta_0 + \beta_1\text{Register}
$$

Given `Register`, the log odds of a null subject versus an overt one is
essentially equivalent to the linear model equation. The model
parameters $\beta_0$ and $\beta_1$ are typically estimated using
**Maximum Likelihood Estimation**[^logistic_regression-3] (MLE).

[^logistic_regression-3]: The goal of the fitting procedure is to
    maximise the likelihood function of the parameter matrix $\ell(\mathbf{\beta})$. Via
    partial differentiation, an intermediary result can be attained
    which can only be solved using an iterative algorithm (e.g.
    Newton-Ralphson). For further technical details, see Wood [-@woodGeneralizedAdditiveModels2006: 63-66] or
    Agresti & Kateri [-@agrestiFoundationsStatisticsData2022: 291-294].

### Multiple logistic regression

If more than one predictor is included, the above equations can be
expanded so as to take into account $p$ slopes $\beta_p$ for $p$
independent variables $X_p$.

$$
\log\left(\frac{P(Y = 1 \mid X_1 + ... + X_p)}{1 - P(Y = 1 \mid X_1 + ... + X_p)}\right) = \frac{e^{\beta_0 + \beta_1X_1 + ... +  \beta_pX_p}}{1 + e^{\beta_0 + \beta_1X_1 + ... + \beta_pX_p}}.
$$ Thus, the log odds correspond to the sum of $\beta_pX_p$,

$$
\begin{aligned}
\log\left(\frac{P(Y = 1 \mid X_p)}{1 - P(Y = 1 \mid X_p)}\right) & = \beta_0 + \beta_1X_1 + ... +  \beta_pX_p \\
& = \beta_0 + \sum_{i=1}^{p} \beta_i X_i
\end{aligned}
$$ respectively.

### Odds ratios

To assess the strength of an effect, it is instructive to examine the
**odds ratios** that correspond to the model coefficients. Odds ratios
(OR) are defined as

$$
OR(X_1) = e^{\beta_1}.
$$

::: {.callout-tip collapse="true" title="Understanding odds ratios"}
Essentially, the OR describes the ratio between two odds with respect to
another independent variable. This is illustrated for `Reference` given
`Register` below:

$$
\text{OR}(\text{Reference} \mid \text{Register}) = \frac{\frac{P(\text{Reference} = \text{null} \mid \text{Register} = \text{S1A})}{P(\text{Reference} = \text{overt} \mid \text{Register} = \text{S1A})}}{\frac{P(\text{Reference} = \text{null} \mid \text{Register} = \text{S1B})}{P(\text{Reference} = \text{overt} \mid \text{Register} = \text{S1B})}}
$$

Read as: '**The ratio between** the probability of a null vs. overt
object in S1A **and** the probability of a null vs. overt object in
S1B'.
:::

## Workflow in R

### Step 1: Research question and hypotheses

How do the intra- and extra-linguistic variables suggested in the
literature affect subject pronoun realisation (Definite Null
Instantiation) in British English, Singapore English and Hong Kong
English?

Given a significance level $\alpha = 0.05$, the hypotheses are: $$ 
\begin{aligned}
H_0: & \quad \text{None of the predictor coefficients deviate from 0}.\\
H_1: & \quad \text{At least one predictor coefficient deviates from 0}.
\end{aligned}
$$

These can be restated mathematically as:

$$ 
\begin{aligned}
H_0: & \quad \beta_1 = \beta_2 = \cdots = \beta_p = 0 \\
H_1: & \quad \text{At least one } \beta_i \neq 0 \text{ for } i \in \{1, 2, \ldots, p\}
\end{aligned} $$

### Step 2: Convert to factors and specify reference levels

The next step involves specifying **reference levels** for all
categorical variables. This step is very important because it will
directly impact the parameter estimation and, consequently, influence
our interpretation of the model output.

-   The reference level of the response is usually chosen such that it
    corresponds to the **unmarked or most frequent case**. Since overt
    pronouns are much more common in the data, the reference level of
    the `Reference` variable will be set to `Reference = overt`. This
    way, the model coefficients will directly represent the probability
    of the **null** **subject** variant (i.e., the special case) given
    certain predictor configurations.

-   The **predictor levels** need to be specified as well. Among other
    things, we are interested in how the Asian Englishes pattern
    relative to British English. Therefore, we will define British
    English as the baseline for comparison.

We will use the following specifications:

| **Variable**   | **Factor Levels**            | **Preferred Reference level** |
|-------------------|--------------------------|---------------------------|
| Register       | S1A, S1B                     | S1A                           |
| Variety        | GB, SING, HK                 | GB                            |
| Person         | 1, 2, 3, *it*, *there*       | 3                             |
| Referentiality | referential, non-referential | referential                   |

```{r, echo = TRUE, output = TRUE}

# Store "Reference" as factor
data_pro$Reference <- as.factor(data_pro$Reference)

## Specify reference level (the 'unmarked' case)
data_pro$Reference <- relevel(data_pro$Reference, "overt")

## Print levels
levels(data_pro$Reference)
```

Repeat the procedure for the remaining categorical variables.

```{r, echo = TRUE, output = TRUE}
#| code-fold: true
#| code-summary: "Code"

# Store "Register" as factor
data_pro$Register <- as.factor(data_pro$Register)

## Specify reference level
data_pro$Register <- relevel(data_pro$Register, "S1A")

# Store "Variety" as factor
data_pro$Variety <- as.factor(data_pro$Variety)

## Specify reference level
data_pro$Variety <- relevel(data_pro$Variety, "GB")

# Store "Person" as factor
data_pro$Person <- as.factor(data_pro$Person)

## Specify reference level
data_pro$Person <- relevel(data_pro$Person, "3")

# Store "Referentiality" as factor
data_pro$Referentiality <- as.factor(data_pro$Referentiality)

## Specify reference level
data_pro$Referentiality <- relevel(data_pro$Referentiality, "referential")


```

### Step 3: Fit the model

There are two functions that can fit logistic models in R: `lrm()` and
`glm()`.

::: callout-note
The model formula below does not include `Referentiality` because
several intermediary steps revealed it to be almost completely
irrelevant for predicting `Reference`. In addition, the existing (and
significant) interaction `Variety:Person` has been excluded to improve
the interpretability of the model.
:::

```{r}
# With lrm(); requires library("rms")

# Fit interaction model
Reference.lrm <- lrm(Reference ~ Register + Variety + Register:Variety + Person, data = data_pro)

# View model statistics
Reference.lrm
```

```{r, echo = TRUE, output = FALSE}
# With (glm); available in base R
# Note the additional "family" argument!
Reference.glm <- glm(Reference ~ Register + Variety + Register:Variety + Person, data = data_pro, family = "binomial")

# View model statistics
summary(Reference.glm)

```

::: callout-tip
## Stepwise variable selection

With the function `drop1()`, it is possible to successively remove
variables from the complex model to ascertain which ones improve the
model significantly (i.e., decrease the deviance and AIC scores).

```{r, echo = TRUE, output = FALSE}

drop1(Reference.glm, test = "Chisq")

```
:::

### Step 4: Confidence intervals and odds ratios

```{r, echo = TRUE, output = TRUE, message = FALSE, warning = FALSE}

# Tidy the model output
tidy_model <- tidy(Reference.glm, conf.int = TRUE)

# Remove intercept, compute odds ratios and their CIs
tidy_model <- tidy_model %>% 
  filter(term != "(Intercept)") %>% 
  mutate(
    odds_ratio = exp(estimate),
    odds.conf.low = exp(conf.low),
    odds.conf.high = exp(conf.high)
  )

```

### Step 5: Visualise the model

Plot model coefficients:

```{r, echo = TRUE, output = TRUE}
#| code-fold: true
#| code-summary: "Code"

# Create the coefficient plot
ggplot(tidy_model, aes(x = estimate, y = term)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "steelblue") +
  theme_minimal() +
  labs(
    x = "Coefficient Estimate (log-odds)",
    y = "Predictor",
    title = "Coefficient Estimates with Confidence Intervals",
    caption = "*Note that the CIs of singificant predictors do not include 0."
  )


# Plot odds ratios
ggplot(tidy_model, aes(x = exp(estimate), y = term)) +
  geom_point() +
  geom_errorbarh(aes(xmin = odds.conf.low, xmax = odds.conf.high), height = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "steelblue") +
  theme_minimal() +
  labs(
    x = "Coefficient Estimate (odds ratios)",
    y = "Predictor",
    title = "Odds ratios with Confidence Intervals",
    caption = "*Note that the CIs of singificant predictors do not include 1."
  )
```


```{r, echo = TRUE, output = TRUE, eval = FALSE, include = FALSE}

# Plot marginal effects; y-axis = log odds of a null vs. overt subject
plot(Effect("Register", mod = Reference.glm)) 
plot(Effect("Variety", mod = Reference.glm))
plot(Effect("Person", mod = Reference.glm))

# Plot interactions
plot(Effect(focal.predictors = c("Register", "Variety"), mod = Reference.glm))
```

Plot predicted probabilities:

```{r}
#| code-fold: true
#| code-summary: "Code"

# Use ggeffect() from the ggeffects package
plot(ggeffect(Reference.glm, terms = c("Register"))) + geom_line(col = "steelblue")

plot(ggeffect(Reference.glm, terms = c("Variety"))) + geom_line(col = "steelblue")

plot(ggeffect(Reference.glm, terms = c("Person"))) + geom_line(col = "steelblue")

```


### Step 6: Interpret the model

The logistic regression model is statistically significant at
$p < 0.001$ ($\chi^2 = 120.43$, $df = 9$) and has acceptable fit
(Nagelkerke's-$R^2$ = $0.09$, $C = 0.73$).

The model coefficients indicate that null subjects are significantly
more likely in Singapore English compared to British English (Estimate =
1.12, 95% CI \[0.56, 1.73\], $p < 0.001$). This effect is moderate with
an $OR$ of 3.06 (95% CI \[1.75, 5.64\]), suggesting that the probability
of subject omission is elevated by a factor of approximately 3 in the
Singaporean variety.

...

### Step 7: Further model diagnostics

-   **Cross-validation**

```{r, echo = TRUE, output = TRUE}
#| code-fold: true
#| code-summary: "Code"

# Refit the model with additional settings
Reference.val <- lrm(Reference ~ Register + Variety + Register:Variety + Person, data = data_pro, x = T, y = T)

# Perform 200-fold cross-validation
model.validated <- validate(Reference.val, B = 200); model.validated 

# Slope optimism should be as low possible!
```

-   **Multicollinearity**

```{r, echo = TRUE, output = TRUE}
#| code-fold: true
#| code-summary: "Code"

# Variable inflation factors further reveal severe multicollinearity
vif(Reference.lrm)
```
