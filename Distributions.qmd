---
title: "Probability distributions"
author: Vladimir Buskin
format:
  html:
    self-contained: true
    theme: default
    toc: true
    number-sections: true
    slide-number: true
    incremental: false
    slide-level: 3
    scrollable: true
editor: visual
bibliography: R.bib
---

```{r, echo = FALSE, output = FALSE}

# Libraries
library("readxl")
library("tidyverse")
library("ggthemes")

# Load data from working directory
#cl.order <- read_xlsx("Paquot_Larsson_2020_data.xlsx")

```

## Suggested reading

> @baguleySeriousStatsGuide2012: Chapter 2
>
> @agrestiFoundationsStatisticsData2022: Chapter 2
>
> @heumann_introduction_2022: Chapter 8

## Continuous distributions

### The normal distribution

A great number of numerical variables in the world follow the well-known
**normal** (or Gaussian) **distribution**, which includes test scores,
weight and height, among many others. The plot below illustrates its
characteristic bell-shape: Most observations are in the middle, with
considerably fewer near the fringes. For example, most people are rather
"average" in height; there are only few people that are extremely short
or extremely tall.

```{r, echo = FALSE, output = TRUE, warning = FALSE, message = FALSE}

# Step 1: Generate data from a normal distribution
set.seed(123) # for reproducibility
data <- rnorm(1000, mean = 0, sd = 1)

# Step 2: Calculate mean and standard deviation
mean_val <- mean(data)
sd_val <- sd(data)

# Step 3: Create a data frame for plotting
x_values <- seq(mean_val - 4*sd_val, mean_val + 4*sd_val, length.out = 1000)
y_values <- dnorm(x_values, mean = mean_val, sd = sd_val)
plot_data <- data.frame(x = x_values, y = y_values)

#Step 4: Plot the normal distribution curve
ggplot(plot_data, aes(x = x, y = y)) +
  geom_line() +
  geom_hline(yintercept = 0) +
  labs(title = "Normal Distribution",
       x = "X",
       y = "Density") +
  theme_minimal()

```

The normal distribution is typically described in terms of two
parameters: The population mean $\mu$ and the population standard
deviation $\sigma$. If a random variable $X$ is normally distributed, we
typically use the notation in @eq-normdistrib.

$$ X \sim N(\mu, \sigma^2).
$$ {#eq-normdistrib}

These two parameters affect the shape of the **probability density
function (PDF)** $f(x)$, which is formally defined as

$$
f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x - \mu)^2}{2 \sigma^2}}.
$$ {#eq-norm-pdf}

In practice, this function returns a bell curve:

```{r, echo = FALSE, output = TRUE, warning = FALSE, message = FALSE}
# Load required libraries
library(ggplot2)

# Step 1: Generate data from a normal distribution
set.seed(123)
data <- rnorm(1000, mean = 0, sd = 1)

# Step 2: Calculate mean and standard deviation
mean_val <- mean(data)
sd_val <- sd(data)

# Step 3: Create a data frame for plotting
x_values <- seq(mean_val - 4*sd_val, mean_val + 4*sd_val, length.out = 1000)
y_values <- dnorm(x_values, mean = mean_val, sd = sd_val)
plot_data <- data.frame(x = x_values, y = y_values)

# Create breaks and labels for x-axis
x_breaks <- c(-3, -2, -1, 0, 1, 2, 3)
x_labels <- c("μ-3σ", "μ-2σ", "μ-σ", "μ = 0", "μ+σ", "μ+2σ", "μ+3σ")

# Step 4: Create the plot with multiple layers
ggplot(plot_data, aes(x = x, y = y)) +
  # Add shaded areas for standard deviations
  stat_function(
    fun = dnorm,
    args = list(mean = mean_val, sd = sd_val),
    xlim = c(mean_val - 3*sd_val, mean_val + 3*sd_val),
    geom = "area",
    fill = "#E3F2FD",
    alpha = 0.3
  ) +
  stat_function(
    fun = dnorm,
    args = list(mean = mean_val, sd = sd_val),
    xlim = c(mean_val - 2*sd_val, mean_val + 2*sd_val),
    geom = "area",
    fill = "#90CAF9",
    alpha = 0.3
  ) +
  stat_function(
    fun = dnorm,
    args = list(mean = mean_val, sd = sd_val),
    xlim = c(mean_val - sd_val, mean_val + sd_val),
    geom = "area",
    fill = "#2196F3",
    alpha = 0.3
  ) +
  # Add the normal distribution curve
  geom_line() +
  # Add vertical line for mean
  geom_vline(xintercept = 0, color = "red", linetype = "dashed") +
  # Add legend annotations
  annotate("text", x = 2, y = 0.35, label = "68.2% (μ ± 1σ)", hjust = 0) +
  annotate("text", x = 2, y = 0.32, label = "95.4% (μ ± 2σ)", hjust = 0) +
  annotate("text", x = 2, y = 0.29, label = "99.7% (μ ± 3σ)", hjust = 0) +
  # Customize the theme and labels
  labs(
    title = "Normal Distribution with Mean μ = 0",
    x = "X",
    y = "Density"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(hjust = 0),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    plot.background = element_blank(),
    axis.text.x = element_text(size = 10),  # Show x-axis text
    axis.ticks.length.x = unit(3, "mm")     # Longer tick marks
  ) +
  # Set appropriate axis limits
  coord_cartesian(xlim = c(-4, 4), ylim = c(0, 0.4)) +
  # Add custom breaks and labels
  scale_x_continuous(breaks = x_breaks, labels = x_labels) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1))
  

```

::: callout-note
## Quick facts about the Gaussian bell curve

Quite interestingly,

-   68% all values fall within one standard deviation of the mean,

-   95% within two, and

-   99.7% within three.
:::

In the plot, the $y$-axis indicates the density of population values;
note that since the Gaussian distribution is a continuous distribution
with technically infinite $x$-values, the probability of any given value
must be 0. We can only obtain probabilities for **intervals** of values,
which are given by

$$
P(a \leq X \leq b) = \int_a^b f(x)dx.
$$ {#eq-norm-prob}

We can find the population mean of $X$ with a PDF $f(x)$ via

$$
E(X) = \mu = \int_x xf(x)dx,
$$ {#eq-norm-mean}

where $E(X)$ denotes the expected value of $X$, i.e., the mean.
Essentially, multiplying every value $x$ by its respective probability
density $f(x)$ and integrating over all possible values of $x$ will
return $E(X) = \mu$.

## Discrete distributions

### Bernoulli distribution

The **Bernoulli distribution** is a discrete probability distribution
for random variables which have only two possible outcomes: "positive"
(often coded as 1) and "negative" (often coded as 0). Examples of such
variables include coin tosses (heads/tails), binary response questions
(yes/no), and defect status (defective/non-defective).

If a random variable $X$ follows a Bernoulli distribution, it is
determined by the parameter $p$, which is the probability of the
positive case:

$$ X \sim Bernoulli(p).$$ The **probability mass function (PMF)** of the
Bernoulli distribution is given by: $$
P(X = x) = 
\begin{cases} 
p & \text{if } x = 1 \\
1 - p & \text{if } x = 0 
\end{cases}
$$

where $0 \leq p \leq 1$. This function shows the probability of $X$
taking on the value of 1 or 0 [cf. @heumann_introduction_2022: 162-163].

```{r, echo = FALSE, output = TRUE}

#Step 1: Define the probability of success
p <- 0.3  # You can change this value to see different scenarios

# Step 2: Create a data frame for the Bernoulli distribution
bernoulli_data <- data.frame(
  outcome = c(0, 1),
  probability = c(1 - p, p)
)

# Step 3: Plot the Bernoulli distribution
ggplot(bernoulli_data, aes(x = factor(outcome), y = probability)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_text(aes(label = round(probability, 2)), vjust = -0.5) +
  labs(title = "Bernoulli Distribution",
       x = "Outcome",
       y = "Probability") +
  theme_minimal()

```

### Binomial Distribution


The **binomial distribution** is a fairly straightforward extension of the Bernoulli distribution in that it models the number of successes in $n$
independent Bernoulli trials, each with probability $p$ of success. If a
random variable $X$ follows a binomial distribution with parameters $n$
and $p$, we write:

$$ X \sim Binomial(n,p) 
$$ {#eq-binom}

The **probability mass function (PMF)** for the binomial distribution
is:

$$ P(X = k) = \binom{n}{k} p^k (1-p)^{n-k} 
$$ {#eq-binom-pmf}

where:

-   $n$ is the number of trials
-   $k$ is the number of successes $(0 \leq k \leq n)$
-   $p$ is the probability of success on each trial $(0 \leq p \leq 1)$
-   $\binom{n}{k}$ is the binomial coefficient ("n choose k")

